<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.23">
<title>LLMs</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/*! Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment the following line when using as a custom stylesheet */
/* @import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700"; */
html{font-family:sans-serif;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
b,strong{font-weight:bold}
abbr{font-size:.9em}
abbr[title]{cursor:help;border-bottom:1px dotted #dddddf;text-decoration:none}
dfn{font-style:italic}
hr{height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type=checkbox],input[type=radio]{padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,::before,::after{box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;line-height:1;position:relative;cursor:auto;-moz-tab-size:4;-o-tab-size:4;tab-size:4;word-wrap:anywhere;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ul.square{list-style-type:square}
ul.circle ul:not([class]),ul.disc ul:not([class]),ul.square ul:not([class]){list-style:inherit}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:1px solid #dedede;word-wrap:normal}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre).nobreak{word-wrap:normal}
:not(pre).nowrap{white-space:nowrap}
:not(pre).pre-wrap{white-space:pre-wrap}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre>code{display:block}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;border-radius:3px;box-shadow:0 1px 0 rgba(0,0,0,.2),inset 0 0 0 .1em #fff;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin:0 auto;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child{border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:flex;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border:1px solid #e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:none;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:hsla(0,0%,100%,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details{margin-left:1.25rem}
details>summary{cursor:pointer;display:block;position:relative;line-height:1.6;margin-bottom:.625rem;outline:none;-webkit-tap-highlight-color:transparent}
details>summary::-webkit-details-marker{display:none}
details>summary::before{content:"";border:solid transparent;border-left:solid;border-width:.3em 0 .3em .5em;position:absolute;top:.5em;left:-1.25rem;transform:translateX(15%)}
details[open]>summary::before{border:solid transparent;border-top:solid;border-width:.5em .3em 0;transform:translateY(15%)}
details>summary::after{content:"";width:1.25rem;height:1em;position:absolute;top:.3em;left:-1.25rem}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class=paragraph]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6);word-wrap:anywhere}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border:1px solid #e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;border-radius:4px}
.sidebarblock{border:1px solid #dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;border-radius:4px}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:first-child,.sidebarblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child,.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{border-radius:4px;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class=highlight],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos,pre.pygments .linenos{border-right:1px solid;opacity:.35;padding-right:.5em;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}
pre.pygments span.linenos{display:inline-block;margin-right:.75em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans-serif;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;font-size:.85rem;text-align:left;margin-right:0}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content{margin-bottom:1.25em;word-wrap:anywhere}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>*>tr>*{border-width:1px}
table.grid-cols>*>tr>*{border-width:0 1px}
table.grid-rows>*>tr>*{border-width:1px 0}
table.frame-all{border-width:1px}
table.frame-ends{border-width:1px 0}
table.frame-sides{border-width:0 1px}
table.frame-none>colgroup+*>:first-child>*,table.frame-sides>colgroup+*>:first-child>*{border-top-width:0}
table.frame-none>:last-child>:last-child>*,table.frame-sides>:last-child>:last-child>*{border-bottom-width:0}
table.frame-none>*>tr>:first-child,table.frame-ends>*>tr>:first-child{border-left-width:0}
table.frame-none>*>tr>:last-child,table.frame-ends>*>tr>:last-child{border-right-width:0}
table.stripes-all>*>tr,table.stripes-odd>*>tr:nth-of-type(odd),table.stripes-even>*>tr:nth-of-type(even),table.stripes-hover>*>tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
li>p:empty:only-child::before{content:"";display:inline-block}
ul.checklist>li>p:first-child{margin-left:-1em}
ul.checklist>li>p:first-child>.fa-square-o:first-child,ul.checklist>li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist>li>p:first-child>input[type=checkbox]:first-child{margin-right:.25em}
ul.inline{display:flex;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
td.hdlist2{word-wrap:anywhere}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:4px solid #fff;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active,#footnotes .footnote a:first-of-type:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);border-radius:50%;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt,summary{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,td.hdlist1,span.alt,summary{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]{border-bottom:1px dotted}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#header,#content,#footnotes,#footer{max-width:none}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media amzn-kf8,print{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
<style>
/*! Stylesheet for CodeRay to loosely match GitHub themes | MIT License */
pre.CodeRay{background:#f7f7f8}
.CodeRay .line-numbers{border-right:1px solid;opacity:.35;padding:0 .5em 0 0;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}
.CodeRay span.line-numbers{display:inline-block;margin-right:.75em}
.CodeRay .line-numbers strong{color:#000}
table.CodeRay{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.CodeRay td{vertical-align:top;line-height:inherit}
table.CodeRay td.line-numbers{text-align:right}
table.CodeRay td.code{padding:0 0 0 .75em}
.CodeRay .debug{color:#fff!important;background:navy!important}
.CodeRay .annotation{color:#007}
.CodeRay .attribute-name{color:navy}
.CodeRay .attribute-value{color:#700}
.CodeRay .binary{color:#509}
.CodeRay .comment{color:#998;font-style:italic}
.CodeRay .char{color:#04d}
.CodeRay .char .content{color:#04d}
.CodeRay .char .delimiter{color:#039}
.CodeRay .class{color:#458;font-weight:bold}
.CodeRay .complex{color:#a08}
.CodeRay .constant,.CodeRay .predefined-constant{color:teal}
.CodeRay .color{color:#099}
.CodeRay .class-variable{color:#369}
.CodeRay .decorator{color:#b0b}
.CodeRay .definition{color:#099}
.CodeRay .delimiter{color:#000}
.CodeRay .doc{color:#970}
.CodeRay .doctype{color:#34b}
.CodeRay .doc-string{color:#d42}
.CodeRay .escape{color:#666}
.CodeRay .entity{color:#800}
.CodeRay .error{color:#808}
.CodeRay .exception{color:inherit}
.CodeRay .filename{color:#099}
.CodeRay .function{color:#900;font-weight:bold}
.CodeRay .global-variable{color:teal}
.CodeRay .hex{color:#058}
.CodeRay .integer,.CodeRay .float{color:#099}
.CodeRay .include{color:#555}
.CodeRay .inline{color:#000}
.CodeRay .inline .inline{background:#ccc}
.CodeRay .inline .inline .inline{background:#bbb}
.CodeRay .inline .inline-delimiter{color:#d14}
.CodeRay .inline-delimiter{color:#d14}
.CodeRay .important{color:#555;font-weight:bold}
.CodeRay .interpreted{color:#b2b}
.CodeRay .instance-variable{color:teal}
.CodeRay .label{color:#970}
.CodeRay .local-variable{color:#963}
.CodeRay .octal{color:#40e}
.CodeRay .predefined{color:#369}
.CodeRay .preprocessor{color:#579}
.CodeRay .pseudo-class{color:#555}
.CodeRay .directive{font-weight:bold}
.CodeRay .type{font-weight:bold}
.CodeRay .predefined-type{color:inherit}
.CodeRay .reserved,.CodeRay .keyword{color:#000;font-weight:bold}
.CodeRay .key{color:#808}
.CodeRay .key .delimiter{color:#606}
.CodeRay .key .char{color:#80f}
.CodeRay .value{color:#088}
.CodeRay .regexp .delimiter{color:#808}
.CodeRay .regexp .content{color:#808}
.CodeRay .regexp .modifier{color:#808}
.CodeRay .regexp .char{color:#d14}
.CodeRay .regexp .function{color:#404;font-weight:bold}
.CodeRay .string{color:#d20}
.CodeRay .string .string .string{background:#ffd0d0}
.CodeRay .string .content{color:#d14}
.CodeRay .string .char{color:#d14}
.CodeRay .string .delimiter{color:#d14}
.CodeRay .shell{color:#d14}
.CodeRay .shell .delimiter{color:#d14}
.CodeRay .symbol{color:#990073}
.CodeRay .symbol .content{color:#a60}
.CodeRay .symbol .delimiter{color:#630}
.CodeRay .tag{color:teal}
.CodeRay .tag-special{color:#d70}
.CodeRay .variable{color:#036}
.CodeRay .insert{background:#afa}
.CodeRay .delete{background:#faa}
.CodeRay .change{color:#aaf;background:#007}
.CodeRay .head{color:#f8f;background:#505}
.CodeRay .insert .insert{color:#080}
.CodeRay .delete .delete{color:#800}
.CodeRay .change .change{color:#66f}
.CodeRay .head .head{color:#f4f}
</style>
</head>
<body class="article">
<div id="header">
<h1>LLMs</h1>
<div id="toc" class="toc">
<div id="toctitle">Índice de contenidos</div>
<ul class="sectlevel1">
<li><a href="#_conceptos_de_ia">1. Conceptos de IA</a>
<ul class="sectlevel2">
<li><a href="#_modelos">1.1. Modelos</a></li>
<li><a href="#_prompts">1.2. Prompts</a></li>
<li><a href="#_prompt_templates">1.3. Prompt Templates</a></li>
<li><a href="#_embedings">1.4. Embedings</a></li>
<li><a href="#_tokens">1.5. Tokens</a></li>
<li><a href="#_output_parsing">1.6. Output parsing</a></li>
<li><a href="#_uso_de_datos_propios_en_modelos_de_ia">1.7. Uso de datos propios en modelos de IA</a></li>
<li><a href="#_retrieval_augmented_generation_rag">1.8. Retrieval Augmented Generation (RAG)</a></li>
<li><a href="#_function_calling">1.9. Function calling</a></li>
<li><a href="#_evaluación_de_respuestas_de_llms">1.10. Evaluación de respuestas de LLMs</a></li>
</ul>
</li>
<li><a href="#_capacidades_de_los_llms">2. Capacidades de los LLMs</a></li>
<li><a href="#_llms_de_propósito_general">3. LLMs de propósito general</a></li>
<li><a href="#_chat_gpt">4. Chat GPT</a>
<ul class="sectlevel2">
<li><a href="#_gpt">4.1. GPT</a></li>
</ul>
</li>
<li><a href="#_spring_ai">5. Spring AI</a>
<ul class="sectlevel2">
<li><a href="#_spring_ai_instalación_y_uso">5.1. Spring AI: instalación y uso</a></li>
<li><a href="#_modelos_soportados_por_spring_ai">5.2. Modelos soportados por Spring AI</a></li>
<li><a href="#_spring_ai_api">5.3. Spring AI API</a>
<ul class="sectlevel3">
<li><a href="#_chat_completion_api">5.3.1. Chat Completion API</a></li>
<li><a href="#_embedings_api">5.3.2. Embedings API</a></li>
<li><a href="#_transcription_api">5.3.3. Transcription API</a></li>
<li><a href="#_ollama_chat_completions_api">5.3.4. Ollama Chat completions API</a></li>
<li><a href="#_ollama_embeddings_api">5.3.5. Ollama Embeddings API</a></li>
<li><a href="#_bases_de_datos_vectoriales_en_spring_ai">5.3.6. Bases de datos vectoriales en Spring AI</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div class="sect1">
<h2 id="_conceptos_de_ia">1. Conceptos de IA</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_modelos">1.1. Modelos</h3>
<div class="paragraph">
<p>Los modelos de IA son algoritmos diseñados para procesar y generar información, a menudo imitando funciones cognitivas humanas. Al aprender patrones y conocimientos de grandes conjuntos de datos, estos modelos pueden hacer predicciones, texto, imágenes u otros resultados, mejorando diversas aplicaciones en diferentes industrias.</p>
</div>
<div class="paragraph">
<p>Hay diferentes tipos de modelos de IA, cada uno adaptado a un caso de uso específico. Mientras que ChatGPT y sus capacidades de IA generativa han cautivado a los usuarios a través de la entrada y salida de texto, muchos modelos y empresas ofrecen entradas y salidas diversas. Antes de ChatGPT, muchas personas estaban fascinadas por los modelos de generación de texto a imagen como Midjourney y Stable Diffusion.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 1. La siguiente tabla muestra algunos ejemplos de modelos de IA y sus aplicaciones:</caption>
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Modelo</th>
<th class="tableblock halign-left valign-top">Aplicación</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ChatGPT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Conversaciones de texto a texto</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SAM</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Segmentación de elementos en imágenes</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stable Diffusion</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Generación de texto a imagen</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Llava</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Detección de objetos en imágenes</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="_prompts">1.2. Prompts</h3>
<div class="paragraph">
<p>Los prompts sirven como la base para las entradas basadas en lenguaje que guían a un modelo de IA para producir salidas específicas. Para aquellos familiarizados con ChatGPT, un prompt podría parecer simplemente el texto introducido en un cuadro de diálogo que se envía a la API. Sin embargo, abarca mucho más que eso. En muchos modelos de IA, el texto del prompt no es solo una cadena simple.</p>
</div>
<div class="paragraph">
<p>La creación de prompts efectivos es tanto un arte como una ciencia. ChatGPT fue diseñado para conversaciones humanas. Esto es bastante diferente de usar algo como SQL para "hacer una pregunta". Uno debe comunicarse con el modelo de IA de manera similar a como se conversa con otra persona.</p>
</div>
<div class="paragraph">
<p>Tal es la importancia de este estilo de interacción que ha surgido el término "Prompt engineering" como su propia disciplina. Existe una creciente colección de técnicas que mejoran la efectividad de los prompts. Invertir tiempo en la creación de un prompt puede mejorar drásticamente el resultado obtenido.</p>
</div>
</div>
<div class="sect2">
<h3 id="_prompt_templates">1.3. Prompt Templates</h3>
<div class="paragraph">
<p>Los prompt templates son plantillas predefinidas que se utilizan para guiar la entrada de texto en un modelo de IA. Estas plantillas proporcionan una estructura y un formato específicos para la entrada de texto, lo que ayuda a los usuarios a crear prompts efectivos y obtener resultados precisos y relevantes.</p>
</div>
<div class="listingblock">
<div class="title">Un ejemplo de prompt template:</div>
<div class="content">
<pre class="CodeRay highlight"><code>Tell me a story about {character} who {action} in {setting}.</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_embedings">1.4. Embedings</h3>
<div class="paragraph">
<p>Los embeddings son representaciones numéricas de palabras, frases o documentos en un espacio vectorial. Estas representaciones se utilizan en modelos de IA para capturar el significado semántico y la relación entre las palabras, lo que permite a los modelos comprender y procesar el lenguaje natural de manera más efectiva.</p>
</div>
<div class="paragraph">
<p>Los embeddings son especialmente relevantes en aplicaciones prácticas como el patrón de Generación con Recuperación Aumentada (RAG). Permiten la representación de datos como puntos en un espacio semántico, que es similar al espacio 2-D de la geometría euclidiana, pero en dimensiones superiores. Esto significa que al igual que los puntos en un plano en la geometría euclidiana pueden estar cerca o lejos según sus coordenadas, en un espacio semántico, la proximidad de los puntos refleja la similitud en el significado. Las oraciones sobre temas similares se posicionan más cerca en este espacio multidimensional, al igual que los puntos que se encuentran cerca entre sí en un gráfico. Esta proximidad ayuda en tareas como la clasificación de texto, la búsqueda semántica e incluso las recomendaciones de productos, ya que permite que la IA distinga y agrupe conceptos relacionados en función de su "ubicación" en este paisaje semántico expandido.</p>
</div>
</div>
<div class="sect2">
<h3 id="_tokens">1.5. Tokens</h3>
<div class="paragraph">
<p>Los tokens son unidades de texto que se utilizan como entradas para modelos de IA. Estas unidades pueden ser palabras, frases, oraciones o párrafos, dependiendo del contexto y la tarea específica que se esté realizando. Los tokens se utilizan para representar información de texto de manera estructurada y procesable por los modelos de IA.</p>
</div>
<div class="paragraph">
<p>En el contexto de los modelos de IA, la facturación se determina por el número de tokens utilizados. Tanto la entrada como la salida contribuyen al recuento total de tokens.</p>
</div>
<div class="paragraph">
<p>También, los modelos están sujetos a límites de tokens, que restringen la cantidad de texto procesado en una sola llamada a la API. Este umbral se conoce a menudo como la 'ventana de contexto'. El modelo no procesa ningún texto que exceda este límite.</p>
</div>
<div class="paragraph">
<p>Por ejemplo, ChatGPT3 tiene un límite de 4K tokens, mientras que GPT4 ofrece opciones variables, como 8K, 16K y 32K. El modelo Claude AI de Anthropic tiene un límite de 100K tokens, y Meta ha obtenido un modelo con un límite de 1M tokens.</p>
</div>
</div>
<div class="sect2">
<h3 id="_output_parsing">1.6. Output parsing</h3>
<div class="paragraph">
<p>El output parsing es el proceso de analizar y procesar las salidas generadas por un modelo de IA para extraer información relevante y presentarla de manera clara y comprensible. Este proceso es fundamental para interpretar y utilizar eficazmente los resultados generados por los modelos de IA en diversas aplicaciones.</p>
</div>
<div class="paragraph">
<p>Output parsing emplea prompts meticulosamente elaborados, a menudo requiriendo múltiples interacciones con el modelo para lograr el formato deseado.</p>
</div>
<div class="paragraph">
<p>Este tipo de escenarios han llevado a OpenAI a introducir 'OpenAI Functions' como un medio para especificar el formato de salida deseado del modelo de manera precisa.</p>
</div>
</div>
<div class="sect2">
<h3 id="_uso_de_datos_propios_en_modelos_de_ia">1.7. Uso de datos propios en modelos de IA</h3>
<div class="olist arabic">
<div class="title">Hay 3 manera de usar datos propios en modelos de IA:</div>
<ol class="arabic">
<li>
<p><strong>Fine-tuning</strong>: Ajustar un modelo pre-entrenado con datos propios para mejorar su rendimiento en tareas específicas.</p>
</li>
<li>
<p><strong>Prompt stuffing</strong>: Incorporar datos propios en los prompts para guiar la generación de texto de un modelo de IA.</p>
</li>
<li>
<p><strong>Function calls</strong>: Llamar a funciones personalizadas que procesen los datos propios y generen salidas específicas en un modelo de IA.</p>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_retrieval_augmented_generation_rag">1.8. Retrieval Augmented Generation (RAG)</h3>
<div class="paragraph">
<p>La generación con recuperación aumentada (RAG) es un enfoque híbrido que combina la generación de lenguaje natural con la recuperación de información para mejorar la calidad y relevancia de las respuestas generadas por los modelos de IA. En lugar de depender únicamente de la generación de texto, RAG utiliza un modelo de recuperación para buscar información relevante en una base de conocimientos y luego genera respuestas basadas en esa información recuperada.</p>
</div>
<div class="paragraph">
<p>Como parte de la carga de los datos no estructurados en la base de datos vectorial, una de las transformaciones más importantes es dividir el documento original en piezas más pequeñas.</p>
</div>
<div class="ulist">
<div class="title">El procedimiento de dividir el documento original en piezas más pequeñas tiene dos pasos importantes:</div>
<ul>
<li>
<p>Separar el documento en partes mientras se preservan los límites semánticos del contenido. Por ejemplo, para un documento con párrafos y tablas, se debe evitar dividir el documento en medio de un párrafo o tabla. Para el código, evitar dividir el código en medio de la implementación de un método.</p>
</li>
<li>
<p>Separar las partes del documento en partes cuyo tamaño sea un pequeño porcentaje del límite de tokens del modelo de IA.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>La siguiente fase en RAG es procesar la entrada del usuario. Cuando una pregunta del usuario debe ser respondida por un modelo de IA, la pregunta y todas las piezas de documento "similares" se colocan en el prompt que se envía al modelo de IA. Esta es la razón para usar una base de datos vectorial. Es muy bueno para encontrar contenido similar.</p>
</div>
<div class="ulist">
<div class="title">Hay varios conceptos que se utilizan en la implementación de RAG. Los conceptos se asignan a clases en Spring AI:</div>
<ul>
<li>
<p><strong>DocumentReader:</strong> Un interfaz funcional de Java que se encarga de cargar una List&lt;Document&gt; desde una fuente de datos. Las fuentes de datos comunes son PDF, Markdown y JSON.</p>
</li>
<li>
<p><strong>Document:</strong> Una representación basada en texto de su fuente de datos que también contiene metadatos para describir el contenido.</p>
</li>
<li>
<p><strong>DocumentTransformer:</strong> Responsable de procesar los datos de diversas maneras (por ejemplo, dividir los documentos en piezas más pequeñas o agregar metadatos adicionales al Document).</p>
</li>
<li>
<p><strong>DocumentWriter:</strong> permite persistir los Documentos en una base de datos (más comúnmente en la pila de IA, una base de datos vectorial).</p>
</li>
<li>
<p><strong>Embedding:</strong> Una representación de sus datos como una List&lt;Double&gt; que es utilizada por la base de datos vectorial para calcular la "similitud" de la consulta de un usuario con documentos relevantes.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_function_calling">1.9. Function calling</h3>
<div class="paragraph">
<p>Los LLMs son inmutables después del entrenamiento, lo que lleva a un conocimiento obsoleto y no pueden acceder o modificar datos externos.</p>
</div>
<div class="paragraph">
<p>El mecanismo de llamada a funciones aborda estas deficiencias. Permite registrar funciones personalizadas que conectan los grandes modelos de lenguaje con las API de sistemas externos. Estos sistemas pueden proporcionar a los LLMs datos en tiempo real y realizar acciones de procesamiento de datos en su nombre.</p>
</div>
<div class="paragraph">
<p>Spring AI simplifica en gran medida el código que necesita escribir para admitir la invocación de funciones. Actúa como intermediario en la conversación de invocación de funciones por usted. Puede proporcionar su función como un @Bean y luego proporcionar el nombre del bean de la función en las opciones de prompt para activar esa función. También puede definir y hacer referencia a múltiples funciones en un solo prompt.</p>
</div>
</div>
<div class="sect2">
<h3 id="_evaluación_de_respuestas_de_llms">1.10. Evaluación de respuestas de LLMs</h3>
<div class="paragraph">
<p>solicitudes de los usuarios es muy importante para garantizar la precisión y utilidad de la aplicación final. Varias técnicas emergentes permiten el uso del modelo preentrenado en sí para este propósito.</p>
</div>
<div class="paragraph">
<p>Esta evaluación implica analizar si la respuesta generada se alinea con la intención del usuario y el contexto de la consulta. Se utilizan métricas como relevancia, coherencia y corrección factual para medir la calidad de la respuesta generada por la IA.</p>
</div>
<div class="paragraph">
<p>Una aproximación implica presentar tanto la solicitud del usuario como la respuesta del modelo de IA al modelo, consultando si la respuesta se alinea con los datos proporcionados.</p>
</div>
<div class="paragraph">
<p>Además, aprovechar la información almacenada en la base de datos vectorial como datos complementarios puede mejorar el proceso de evaluación, ayudando a determinar la relevancia de la respuesta.</p>
</div>
<div class="paragraph">
<p>El proyecto Spring AI actualmente proporciona algunos ejemplos muy básicos de cómo puede evaluar las respuestas en forma de prompts para incluir en una prueba JUnit.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_capacidades_de_los_llms">2. Capacidades de los LLMs</h2>
<div class="sectionbody">
<div class="ulist">
<div class="title">Los LLMs se clasifican de acuerdo a estos criterios:</div>
<ul>
<li>
<p>Generales</p>
<div class="ulist">
<ul>
<li>
<p>MMLU Representación de cuestiones de 57 materias (humanidades, ciencias sociales, ciencias naturales, matemáticas, tecnología, etc.)</p>
</li>
</ul>
</div>
</li>
<li>
<p>Razonamiento</p>
<div class="ulist">
<ul>
<li>
<p>Un gran test de datos de tareas desafiantes que requieren razonamiento de múltiples pasos</p>
</li>
<li>
<p>DROP Compprensión de lectura (F1 Score)</p>
</li>
<li>
<p>HellaSwag razonamiento de sentido común para tareas cotidianas</p>
</li>
</ul>
</div>
</li>
<li>
<p>Matemáticas</p>
<div class="ulist">
<ul>
<li>
<p>GSM8K Aritmética básica (incluye problemas de matemáticas de primaria)</p>
</li>
<li>
<p>MATH Challenging Retos matemáticos (incluye álgebra, geometría, pre-cálculo y otros)</p>
</li>
</ul>
</div>
</li>
<li>
<p>Código</p>
<div class="ulist">
<ul>
<li>
<p>Generación de código HumanEval Python</p>
</li>
<li>
<p>Generación de código de Python de HumanEval. Nuevo conjunto de datos retenido similar a HumanEval, no filtrado en la web</p>
</li>
</ul>
</div>
</li>
<li>
<p>Imágenes (multimodal)</p>
<div class="ulist">
<ul>
<li>
<p>MMMU razonamiento de problemas de nivel universitario de múltiples disciplinas</p>
</li>
<li>
<p>VQAv2 Comprensión de imágenes naturales</p>
</li>
<li>
<p>TextVQA OCR reconocimiento de objetos en imágenes naturales</p>
</li>
<li>
<p>DocVQA Comprensión de documentos</p>
</li>
<li>
<p>Infographic VQA comprensión de infografías</p>
</li>
<li>
<p>MathVista razonamiento matemático en contextos visuales</p>
</li>
<li>
<p>MathVQA2 razonamiento matemático en contextos visuales (incluye problemas de matemáticas de primaria)</p>
</li>
</ul>
</div>
</li>
<li>
<p>Texto (imodal)</p>
<div class="ulist">
<ul>
<li>
<p>MMTU Comprensión de texto naturales</p>
</li>
<li>
<p>VQAText OCR reconocimiento de palabras en imágenes naturales</p>
</li>
<li>
<p>DocText Comprensión de documentos</p>
</li>
<li>
<p>Infographic TextVQA comprensión de infografías</p>
</li>
</ul>
</div>
</li>
<li>
<p>Audio (multimodal)</p>
<div class="ulist">
<ul>
<li>
<p>MMAU Comprensión de audio naturales</p>
</li>
<li>
<p>VQAAudio OCR reconocimiento de palabras en imágenes naturales</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Los LLMs se clasifican de acuerdo a estas capacidades:</div>
<ol class="arabic">
<li>
<p><strong>Comprensión (Comprehension):</strong></p>
<div class="ulist">
<ul>
<li>
<p>POS Tagging (Part-of-Speech): Evalúa la precisión al identificar las categorías gramaticales de cada palabra.</p>
</li>
<li>
<p>Named Entity Recognition (NER): Mide la habilidad para reconocer y clasificar entidades nombradas dentro del texto.</p>
</li>
<li>
<p>Question Answering: Comprueba la capacidad para responder preguntas con precisión, basándose en contextos proporcionados.</p>
</li>
<li>
<p>Commonsense Reasoning: Evalúa la habilidad para resolver problemas y hacer inferencias razonables.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Generación de Texto (Text Generation):</strong></p>
<div class="ulist">
<ul>
<li>
<p>Coherence and Cohesion: Mide la capacidad para generar texto coherente y cohesivo, con transiciones adecuadas entre oraciones.</p>
</li>
<li>
<p>Grammar and Fluency: Evalúa la gramática y fluidez del texto generado.</p>
</li>
<li>
<p>Creativity: Comprueba la habilidad para generar contenido creativo o variado.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Comunicación (Communication):</strong></p>
<div class="ulist">
<ul>
<li>
<p>Dialogue Generation: Mides la capacidad para generar diálogos naturales y adecuados.</p>
</li>
<li>
<p>Summarization: Evalúa la habilidad para resumir textos de manera precisa y relevante.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Conocimiento y Factualidad (Knowledge and Factuality):</strong></p>
<div class="ulist">
<ul>
<li>
<p>Knowledge Base Question Answering: Comprueba si el modelo puede acceder a su base de conocimientos para responder preguntas correctamente.</p>
</li>
<li>
<p>Fact Verification: Evalúa la capacidad del modelo para confirmar o refutar hechos y datos.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Traducción (Translation):</strong></p>
<div class="ulist">
<ul>
<li>
<p>Multilingual Ability: Mides la habilidad para traducir entre diferentes idiomas con precisión y fidelidad al texto original.</p>
</li>
<li>
<p>Zero-Shot Translation: Evalúa la capacidad del modelo para realizar traducciones sin entrenamiento previo en parejas de idiomas específicas.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Inferencia (Inference):</strong></p>
<div class="ulist">
<ul>
<li>
<p>Entailment and Paradox Detection: Comprueba la habilidad para detectar lógica y resolver paradójos.</p>
</li>
<li>
<p>Causal Reasoning: Evalúa la capacidad para entender causas y efectos en el texto.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Multimodality (Multimodality):</strong></p>
<div class="ulist">
<ul>
<li>
<p>Image Captioning: Mide si el modelo puede describir imágenes de manera coherente y precisa.</p>
</li>
<li>
<p>Grounded Language (Visual/Audio Commands, etc.): Evalúa la habilidad para interpretar y responder a comandos basados en imágenes o sonidos.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Generalization and Adaptation (Generalization and Adaptation):</strong></p>
<div class="ulist">
<ul>
<li>
<p>Domain Adaptation: Comprueba cómo el modelo adapta su conocimiento a diferentes dominios de conocimiento.</p>
</li>
<li>
<p>Out-of-Distribution Generalization: Evalúa la capacidad del modelo para generalizar a datos que no están en el conjunto de entrenamiento original.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Bias and Fairness (Bias and Fairness):</strong></p>
<div class="ulist">
<ul>
<li>
<p>Bias Detection and Mitigation: Identifica y evalúa cómo se manejan los sesgos presentes en los datos de entrenamiento.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Robustness and Reliability (Robustness and Reliability):</strong></p>
<div class="ulist">
<ul>
<li>
<p>Robustness to Adversarial Attacks: Evalúa la capacidad del modelo para resistir ataques adversarios diseñados para confundir o engañar al modelo.</p>
</li>
<li>
<p>Model Interpretability: Comprueba si se pueden entender las respuestas y decisiones tomadas por el modelo.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Human Evaluation (Human Evaluation):</strong></p>
<div class="ulist">
<ul>
<li>
<p>Human-in-the-Loop Evaluations: Utiliza a los usuarios humanos para evaluar la calidad de las respuestas generadas o comprender mejor cómo se perciben las interacciones con el modelo.</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_llms_de_propósito_general">3. LLMs de propósito general</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Un LLM de propósito general es un modelo de lenguaje que puede ser utilizado para una amplia variedad de tareas de procesamiento de lenguaje natural. Estos modelos son entrenados en grandes cantidades de datos y son capaces de realizar tareas como generación de texto, traducción automática, resumen de texto, entre otras.</p>
</div>
<div class="ulist">
<div class="title">Aplicaciones de los LLMs de propósito general:</div>
<ul>
<li>
<p>Chatbots.</p>
</li>
<li>
<p>Asistentes virtuales.</p>
</li>
<li>
<p>Traducción automática.</p>
</li>
<li>
<p>Autocompletado de texto.</p>
</li>
<li>
<p>RAG (Retrieve, Answer, Generate).</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">Podemos establecer dos categorías de LLMs de propósito general:</div>
<ul>
<li>
<p><strong>LLMs privativos</strong>: son aquellos que no están disponibles para el público en general.</p>
<div class="ulist">
<ul>
<li>
<p>GPT-3</p>
</li>
<li>
<p>BERT</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>LLMs de código abierto</strong>: son aquellos que están disponibles para el público en general.</p>
<div class="ulist">
<ul>
<li>
<p>Llama</p>
</li>
<li>
<p>Mistral</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<div class="title">Una referencia para ver el rendimiento de los LLMs de propósito general:</div>
<p><a href="https://huggingface.co/spaces/andrewrreed/closed-vs-open-arena-elo" class="bare">https://huggingface.co/spaces/andrewrreed/closed-vs-open-arena-elo</a></p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_chat_gpt">4. Chat GPT</h2>
<div class="sectionbody">
<div class="paragraph">
<p>ChatGPT es una inteligencia artificial diseñada para mantener conversaciones con usuarios humanos. Utiliza el aprendizaje automático para comprender el lenguaje humano y generar respuestas coherentes y relevantes en función de las entradas de texto que recibe. En resumen, es como tener una charla con una máquina inteligente.</p>
</div>
<div class="paragraph">
<p>ChatGPT se basa en la arquitectura GPT (Generative Pre-trained Transformer), desarrollada por OpenAI. Hasta mi última actualización en enero de 2022, existían varias versiones de ChatGPT que se basaban en diferentes versiones de la arquitectura GPT, incluyendo GPT-3.5, que es la versión en la que estoy basado.</p>
</div>
<div class="olist arabic">
<div class="title">Las prestaciones de ChatGPT incluyen:</div>
<ol class="arabic">
<li>
<p><strong>Generación de texto coherente y relevante:</strong> Puede comprender el contexto de una conversación y generar respuestas que se ajusten a ese contexto.</p>
</li>
<li>
<p><strong>Flexibilidad en el lenguaje:</strong> Puede manejar una amplia variedad de temas y estilos de conversación, desde preguntas técnicas hasta conversaciones informales.</p>
</li>
<li>
<p><strong>Adaptabilidad:</strong> A medida que se le proporciona más información y datos, ChatGPT puede mejorar su capacidad para responder de manera más precisa y relevante.</p>
</li>
<li>
<p><strong>Aplicaciones en múltiples campos:</strong> Se puede utilizar para una variedad de aplicaciones, como asistencia al cliente, generación de contenido, enseñanza y más.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>En general, las prestaciones de ChatGPT están orientadas a proporcionar una experiencia de conversación fluida y natural con los usuarios, ayudando a facilitar la comunicación entre humanos y máquinas.</p>
</div>
<div class="sect2">
<h3 id="_gpt">4.1. GPT</h3>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 2. Aquí tienes un resumen de las principales versiones de modelos GPT que se han utilizado en ChatGPT, junto con sus fechas de publicación:</caption>
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Modelo</th>
<th class="tableblock halign-left valign-top">Fecha de Publicación</th>
<th class="tableblock halign-left valign-top">Descripción</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">GPT-1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2018</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">La primera versión del modelo GPT, introducida por OpenAI.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">GPT-2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2019</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Una versión más grande y potente que GPT-1, con 1.5 mil millones de parámetros.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">GPT-3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2020</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Un salto significativo en tamaño y rendimiento, con 175 mil millones de parámetros y capacidades de generación avanzadas.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">GPT-3.5</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2021</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Una mejora incremental de GPT-3 con correcciones de errores y ajustes de rendimiento.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">GPT-4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2023</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Una versión más avanzada y potente que GPT-3, con mejoras en la generación de lenguaje natural y la capacidad de razonamiento.</p></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_spring_ai">5. Spring AI</h2>
<div class="sectionbody">
<div class="paragraph">
<p>El proyecto Spring AI tiene como objetivo simplificar el desarrollo de aplicaciones que incorporan funcionalidades de inteligencia artificial sin complejidades innecesarias.</p>
</div>
<div class="paragraph">
<p>El proyecto se inspira en proyectos de Python como LangChain y LlamaIndex, pero Spring AI no es un puerto directo de esos proyectos. El proyecto se fundó con la creencia de que la próxima ola de aplicaciones de IA generativa no será solo para desarrolladores de Python, sino que será ubicua en muchos lenguajes de programación.</p>
</div>
<div class="paragraph">
<p>En su núcleo, Spring AI proporciona abstracciones que sirven como base para el desarrollo de aplicaciones de IA. Estas abstracciones tienen múltiples implementaciones, lo que permite cambiar fácilmente los componentes con cambios mínimos en el código.</p>
</div>
<div class="ulist">
<div class="title">Spring AI proporciona las siguientes características:</div>
<ul>
<li>
<p>Soporte para todos los principales proveedores de modelos como OpenAI, Microsoft, Amazon, Google y Huggingface.</p>
</li>
<li>
<p>Los tipos de modelos soportados son Chat y Text to Image, con más en camino.</p>
</li>
<li>
<p>Un API portable entre proveedores de IA para Chat y para modelos de incrustación. Se admiten opciones de API síncronas y de transmisión. También se admite la posibilidad de acceder a características específicas del modelo.</p>
</li>
<li>
<p>Mapeo de la salida del modelo de IA a POJOs (Plain Old Java Objects) para facilitar el uso de los resultados en aplicaciones Java.</p>
</li>
<li>
<p>Soporte para todos los principales proveedores de bases de datos vectoriales como Azure Vector Search, Chroma, Milvus, Neo4j, PostgreSQL/PGVector, PineCone, Qdrant, Redis y Weaviate</p>
</li>
<li>
<p>API portable entre proveedores de almacenamiento de vectores, incluido un nuevo API de filtro de metadatos similar a SQL que también es portátil.</p>
</li>
<li>
<p>Llamadas a funciones de IA en tiempo real</p>
</li>
<li>
<p>Auto-configuración de Spring Boot y Starters para modelos de IA y vector stores</p>
</li>
<li>
<p>Framework ETL para Ingeniería de Datos</p>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="_spring_ai_instalación_y_uso">5.1. Spring AI: instalación y uso</h3>
<div class="paragraph">
<p>Podemos usar el cliente de Spring Boot para instalar y usar Spring AI.
Está disponible en el repositorio del proyecto en GitHub:
<a href="https://github.com/spring-projects/spring-cli/releases" class="bare">https://github.com/spring-projects/spring-cli/releases</a></p>
</div>
<div class="paragraph">
<p>Para instalar Spring AI, simplemente descarga el archivo ejecutable para tu sistema operativo y sigue las instrucciones de instalación. Una vez instalado, puedes usar el comando <code>spring</code> para gestionar aplicaciones de Spring y acceder a las funcionalidades de Spring AI.</p>
</div>
<div class="listingblock">
<div class="title">Con este comando podemos crear un nuevo proyecto de Spring AI:</div>
<div class="content">
<pre class="CodeRay highlight"><code>spring boot new --from ai --name myai</code></pre>
</div>
</div>
<div class="paragraph">
<p>Es necesario definir un archivo de configuración <code>application.properties</code> para especificar las credenciales y configuraciones necesarias para acceder a los servicios de IA y bases de datos vectoriales.</p>
</div>
<div class="listingblock">
<div class="title">Aquí tienes un ejemplo de cómo podría ser un archivo de configuración <code>application.properties</code> para Spring AI:</div>
<div class="content">
<pre class="CodeRay highlight"><code>spring.ai.openai.api-key = &lt;API_KEY&gt;
spring.ai.openai.chat.options.model=gpt-3.5-turbo
spring.ai.openai.chat.options.temperature=0.7</code></pre>
</div>
</div>
<div class="paragraph">
<p>Este mismo proceso se puede hacer con la herramienta online spring initializer: <a href="https://start.spring.io/" class="bare">https://start.spring.io/</a></p>
</div>
</div>
<div class="sect2">
<h3 id="_modelos_soportados_por_spring_ai">5.2. Modelos soportados por Spring AI</h3>
<div class="ulist">
<ul>
<li>
<p><strong>Chat Completion API</strong></p>
<div class="ulist">
<ul>
<li>
<p>OpenAI Chat Completion</p>
</li>
<li>
<p>Microsoft Azure Open AI Chat Completion</p>
</li>
<li>
<p>Ollama Chat Completion</p>
</li>
<li>
<p>HuggingFace Chat Completion</p>
</li>
<li>
<p>Google Vertex AI PaLM2 Chat Completion</p>
</li>
<li>
<p>Google Vertex AI Gemini Chat Completion</p>
</li>
<li>
<p>Amazon Bedrock</p>
<div class="ulist">
<ul>
<li>
<p>Cohere Chat Completion</p>
</li>
<li>
<p>Llama2 Chat Completion</p>
</li>
<li>
<p>Titan Chat Completion</p>
</li>
<li>
<p>Anthropic Chat Completion</p>
</li>
</ul>
</div>
</li>
<li>
<p>MistralAI Chat Completion</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Transcription API</strong></p>
<div class="ulist">
<ul>
<li>
<p>OpenAI Transcription (Whisper)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Image Generation API</strong></p>
<div class="ulist">
<ul>
<li>
<p>OpenAI Image Generation</p>
</li>
<li>
<p>StabilityAI Image Generation</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Embeddings API</strong></p>
<div class="ulist">
<ul>
<li>
<p>Spring AI OpenAI Embeddings</p>
</li>
<li>
<p>Spring AI Azure OpenAI Embeddings</p>
</li>
<li>
<p>Spring AI Ollama Embeddings</p>
</li>
<li>
<p>Spring AI Transformers (ONNX) Embeddings</p>
</li>
<li>
<p>Spring AI PostgresML Embeddings</p>
</li>
<li>
<p>Spring AI Bedrock Cohere Embeddings</p>
</li>
<li>
<p>Spring AI Bedrock Titan Embeddings</p>
</li>
<li>
<p>Spring AI VertexAI Embeddings</p>
</li>
<li>
<p>Spring AI MistralAI Embeddings</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Vector Database API</strong></p>
<div class="ulist">
<ul>
<li>
<p>Azure Vector Search</p>
</li>
<li>
<p>ChromaVectorStore</p>
</li>
<li>
<p>MilvusVectorStore</p>
</li>
<li>
<p>Neo4jVectorStore</p>
</li>
<li>
<p>PgVectorStore</p>
</li>
<li>
<p>PineconeVectorStore</p>
</li>
<li>
<p>QdrantVectorStore</p>
</li>
<li>
<p>RedisVectorStore</p>
</li>
<li>
<p>WeaviateVectorStore</p>
</li>
<li>
<p>SimpleVectorStore</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_spring_ai_api">5.3. Spring AI API</h3>
<div class="paragraph">
<p>El API de Spring AI cubre una amplia gama de funcionalidades. Cada característica principal se detalla en su propia sección dedicada. Para proporcionar una visión general.</p>
</div>
<div class="ulist">
<div class="title">Las siguientes funcionalidades clave están disponibles:</div>
<ul>
<li>
<p>API reutilizable a través de proveedores de IA para Chat, Text to Image y modelos de Embedding. Se admiten opciones de API síncronas y de transmisión. También se admite la posibilidad de acceder a características específicas del modelo. Admitimos modelos de IA de OpenAI, Microsoft, Amazon, Google, Huggingface y más.</p>
</li>
<li>
<p>API portable entre proveedores de almacenamiento de vectores, incluido un nuevo API de filtro de metadatos similar a SQL que también es portátil. Se admiten 8 bases de datos vectoriales.</p>
</li>
<li>
<p>Llamadas a funciones de IA en tiempo real. Spring AI facilita que el modelo de IA invoque su objeto java.util.Function POJO.</p>
</li>
<li>
<p>Auto-configuración de Spring Boot y Starters para modelos de IA y vector stores.</p>
</li>
<li>
<p>Framework ETL para Ingeniería de Datos. Esto proporciona la base para cargar datos en una base de datos vectorial, ayudando a implementar el patrón de Generación con Recuperación Aumentada que le permite llevar sus datos al modelo de IA para incorporarlos en su respuesta.</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_chat_completion_api">5.3.1. Chat Completion API</h4>
<div class="paragraph">
<p>El Chat Completion API de Spring AI proporciona una interfaz unificada para interactuar con varios proveedores de modelos de chat, como OpenAI, Microsoft, Amazon, Google, Huggingface y más. Con esta API, los desarrolladores pueden enviar solicitudes de texto a un modelo de chat alojado en la nube y recibir respuestas generadas por el modelo en tiempo real.</p>
</div>
<div class="paragraph">
<p>El API funciona enviando un prompt o una conversación parcial al modelo de IA, que luego genera una completación o continuación de la conversación basada en sus datos de entrenamiento y su comprensión de los patrones del lenguaje natural. La respuesta completada se devuelve a la aplicación, que puede presentarla al usuario o utilizarla para un procesamiento adicional.</p>
</div>
<div class="paragraph">
<p>Éste API es útil para una variedad de aplicaciones, como chatbots, asistentes virtuales, soporte al cliente automatizado, juegos de texto y más. Permite a los desarrolladores aprovechar la potencia de los modelos de lenguaje natural para mejorar la interacción humano-máquina en sus propios productos y servicios.</p>
</div>
<div class="ulist">
<div class="title">Los objetivos de la API de Chat Completion son:</div>
<ul>
<li>
<p>ChatClient</p>
</li>
<li>
<p>StreamingChatClient</p>
</li>
<li>
<p>Prompt</p>
</li>
<li>
<p>Message</p>
</li>
<li>
<p>ChatOptions</p>
</li>
<li>
<p>ChatResponse</p>
</li>
<li>
<p>Generation</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">La definición del interfaz de ChatClient es:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">interface</span> <span class="class">ChatClient</span> <span class="directive">extends</span> ModelClient&lt;Prompt, ChatResponse&gt; {

        <span class="keyword">default</span> <span class="predefined-type">String</span> call(<span class="predefined-type">String</span> message) {<span class="comment">// implementation omitted</span>
        }

    <span class="annotation">@Override</span>
        ChatResponse call(Prompt prompt);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Donde <code>Prompt</code> es la entrada al modelo de IA y <code>ChatResponse</code> es la salida generada por el modelo. La interfaz <code>ChatClient</code> define un método <code>call</code> que toma un <code>Prompt</code> y devuelve un <code>ChatResponse</code>. La implementación de este método varía según el proveedor de IA subyacente.</p>
</div>
<div class="listingblock">
<div class="title">La definición de la interfaz <code>StreamingChatClient</code> es:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">interface</span> <span class="class">StreamingChatClient</span> <span class="directive">extends</span> StreamingModelClient&lt;Prompt, ChatResponse&gt; {
    <span class="annotation">@Override</span>
        Flux&lt;ChatResponse&gt; stream(Prompt prompt);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Donde <code>Flux&lt;ChatResponse&gt;</code> es un flujo de respuestas generadas por el modelo de IA. La interfaz <code>StreamingChatClient</code> define un método <code>stream</code> que toma un <code>Prompt</code> y devuelve un <code>Flux&lt;ChatResponse&gt;</code>. Este método permite la generación de respuestas en tiempo real a medida que se reciben las entradas. No todos los servicios de IA admiten la transmisión de respuestas en tiempo real.</p>
</div>
<div class="listingblock">
<div class="title">La definición de la clase <code>Prompt</code> es:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">class</span> <span class="class">Prompt</span> <span class="directive">implements</span> ModelRequest&lt;<span class="predefined-type">List</span>&lt;Message&gt;&gt; {

    <span class="directive">private</span> <span class="directive">final</span> <span class="predefined-type">List</span>&lt;Message&gt; messages;

    <span class="directive">private</span> ChatOptions modelOptions;

        <span class="annotation">@Override</span>
        <span class="directive">public</span> ChatOptions getOptions() {..}

        <span class="annotation">@Override</span>
        <span class="directive">public</span> <span class="predefined-type">List</span>&lt;Message&gt; getInstructions() {...}

    <span class="comment">// constructors and utility methods omitted</span>
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Donde <code>Message</code> es un mensaje de texto en una conversación y <code>ChatOptions</code> son las opciones de configuración del modelo de IA. La clase <code>Prompt</code> implementa la interfaz <code>ModelRequest</code> y proporciona métodos para acceder a los mensajes y opciones de configuración.</p>
</div>
<div class="listingblock">
<div class="title">La definición de la clase <code>Message</code> es:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">interface</span> <span class="class">Message</span> {

        <span class="predefined-type">String</span> getContent();

        <span class="predefined-type">List</span>&lt;<span class="predefined-type">Media</span>&gt; getMedia();

        <span class="predefined-type">Map</span>&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Object</span>&gt; getProperties();

        MessageType getMessageType();

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Donde <code>MessageType</code> es un enumerador que define el tipo de mensaje, como entrada del usuario, respuesta del modelo, etc. La interfaz <code>Message</code> define métodos para acceder al contenido del mensaje, las propiedades asociadas y el tipo de mensaje.</p>
</div>
<div class="listingblock">
<div class="title">La definición del interfaz <code>ChatOptions</code> es:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">interface</span> <span class="class">ChatOptions</span> <span class="directive">extends</span> ModelOptions {

        <span class="predefined-type">Float</span> getTemperature();
        <span class="type">void</span> setTemperature(<span class="predefined-type">Float</span> temperature);
        <span class="predefined-type">Float</span> getTopP();
        <span class="type">void</span> setTopP(<span class="predefined-type">Float</span> topP);
        <span class="predefined-type">Integer</span> getTopK();
        <span class="type">void</span> setTopK(<span class="predefined-type">Integer</span> topK);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Donde <code>ModelOptions</code> es una interfaz que define las opciones de configuración del modelo de IA. La interfaz <code>ChatOptions</code> extiende <code>ModelOptions</code> y proporciona métodos para acceder y configurar parámetros específicos del modelo de chat, como la temperatura, <code>topP</code> y <code>topK</code>.</p>
</div>
<div class="listingblock">
<div class="title">La definición de la clase <code>ChatResponse</code> es:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">class</span> <span class="class">ChatResponse</span> <span class="directive">implements</span> ModelResponse&lt;Generation&gt; {

    <span class="directive">private</span> <span class="directive">final</span> ChatResponseMetadata chatResponseMetadata;
        <span class="directive">private</span> <span class="directive">final</span> <span class="predefined-type">List</span>&lt;Generation&gt; generations;

        <span class="annotation">@Override</span>
        <span class="directive">public</span> ChatResponseMetadata getMetadata() {...}

    <span class="annotation">@Override</span>
        <span class="directive">public</span> <span class="predefined-type">List</span>&lt;Generation&gt; getResults() {...}

    <span class="comment">// other methods omitted</span>
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Donde <code>ChatResponseMetadata</code> es un objeto que contiene metadatos sobre la respuesta generada por el modelo de IA y <code>Generation</code> es una generación de texto en la conversación. La clase <code>ChatResponse</code> implementa la interfaz <code>ModelResponse</code> y proporciona métodos para acceder a los metadatos y generaciones de la respuesta.</p>
</div>
<div class="listingblock">
<div class="title">La definición de la clase <code>Generation</code> es:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">class</span> <span class="class">Generation</span> <span class="directive">implements</span> ModelResult&lt;AssistantMessage&gt; {

        <span class="directive">private</span> AssistantMessage assistantMessage;
        <span class="directive">private</span> ChatGenerationMetadata chatGenerationMetadata;

        <span class="annotation">@Override</span>
        <span class="directive">public</span> AssistantMessage getOutput() {...}

        <span class="annotation">@Override</span>
        <span class="directive">public</span> ChatGenerationMetadata getMetadata() {...}

    <span class="comment">// other methods omitted</span>
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Donde <code>AssistantMessage</code> es un mensaje generado por el modelo de IA y <code>ChatGenerationMetadata</code> son metadatos asociados con la generación de texto. La clase <code>Generation</code> implementa la interfaz <code>ModelResult</code> y proporciona métodos para acceder al mensaje y metadatos generados.</p>
</div>
<div class="paragraph">
<p>Inicialmente, los prompts eran cadenas simples, solo líneas de texto. Con el tiempo, esto evolucionó para incluir marcadores de posición específicos dentro de estas cadenas, como "USUARIO:", que el modelo de IA podía reconocer y responder en consecuencia. Este fue un paso hacia prompts más estructurados.</p>
</div>
<div class="paragraph">
<p>Los roles categorizan los mensajes, aclarando el contexto y el propósito de cada segmento del prompt para el modelo de IA. Este enfoque estructurado mejora el matiz y la eficacia de la comunicación con la IA, ya que cada parte del prompt desempeña un papel distinto y definido en la interacción.</p>
</div>
<div class="ulist">
<div class="title">Los roles comunes en los prompts estructurados son:</div>
<ul>
<li>
<p><strong>System Role:</strong> Guía el comportamiento del AI y el estilo de respuesta, estableciendo parámetros o reglas para cómo el AI interpreta y responde a la entrada. Es similar a proporcionar instrucciones al AI antes de iniciar una conversación.</p>
</li>
<li>
<p><strong>User Role:</strong> Representa la entrada del usuario (sus preguntas, comandos o declaraciones a la IA). Este rol es fundamental ya que forma la base de la respuesta del AI.</p>
</li>
<li>
<p><strong>Assistant Role:</strong> La respuesta del AI a la entrada del usuario. Más que una respuesta o reacción, es crucial para mantener el flujo de la conversación. Al rastrear las respuestas anteriores del AI (sus mensajes de 'Assistant Role'), el sistema garantiza interacciones coherentes y contextualmente relevantes.</p>
</li>
<li>
<p><strong>Function Role:</strong> Este rol se ocupa de tareas u operaciones específicas durante la conversación. Mientras que el Rol del Sistema establece el comportamiento general del AI, el Rol de la Función se centra en llevar a cabo ciertas acciones o comandos que el usuario solicita. Es como una característica especial en el AI, utilizada cuando sea necesario para realizar funciones específicas como cálculos, obtención de datos u otras tareas más allá de simplemente hablar. Este rol permite al AI ofrecer ayuda práctica además de respuestas conversacionales.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Los roles se representan en Spring AI como un enmu:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">enum</span> MessageType {

        USER(<span class="string"><span class="delimiter">&quot;</span><span class="content">user</span><span class="delimiter">&quot;</span></span>),

        ASSISTANT(<span class="string"><span class="delimiter">&quot;</span><span class="content">assistant</span><span class="delimiter">&quot;</span></span>),

        SYSTEM(<span class="string"><span class="delimiter">&quot;</span><span class="content">system</span><span class="delimiter">&quot;</span></span>),

        FUNCTION(<span class="string"><span class="delimiter">&quot;</span><span class="content">function</span><span class="delimiter">&quot;</span></span>);

        <span class="directive">private</span> <span class="directive">final</span> <span class="predefined-type">String</span> value;

        MessageType(<span class="predefined-type">String</span> value) {
                <span class="local-variable">this</span>.value = value;
        }

        <span class="directive">public</span> <span class="predefined-type">String</span> getValue() {
                <span class="keyword">return</span> value;
        }

        <span class="directive">public</span> <span class="directive">static</span> MessageType fromValue(<span class="predefined-type">String</span> value) {
                <span class="keyword">for</span> (MessageType messageType : MessageType.values()) {
                        <span class="keyword">if</span> (messageType.getValue().equals(value)) {
                                <span class="keyword">return</span> messageType;
                        }
                }
                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="exception">IllegalArgumentException</span>(<span class="string"><span class="delimiter">&quot;</span><span class="content">Invalid MessageType value: </span><span class="delimiter">&quot;</span></span> + value);
        }

}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">La clase PromptTemplate está diseñada para facilitar la creación de prompts estructurados que luego se envían al modelo de IA para su procesamiento.</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">class</span> <span class="class">PromptTemplate</span> <span class="directive">implements</span> PromptTemplateActions, PromptTemplateMessageActions {

   <span class="predefined-type">String</span> render(); <span class="comment">//PromptTemplateStringActions</span>

        <span class="predefined-type">String</span> render(<span class="predefined-type">Map</span>&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Object</span>&gt; model); <span class="comment">//PromptTemplateStringActions</span>

   Message createMessage(); <span class="comment">//PromptTemplateMessageActions</span>

        Message createMessage(<span class="predefined-type">Map</span>&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Object</span>&gt; model); <span class="comment">//PromptTemplateMessageActions</span>

   Prompt create(); <span class="comment">//PromptTemplateActions</span>

        Prompt create(<span class="predefined-type">Map</span>&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Object</span>&gt; model); <span class="comment">//PromptTemplateActions</span>
}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Ejemplo de uso de PromptTemplate:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">PromptTemplate promptTemplate = <span class="keyword">new</span> PromptTemplate(<span class="string"><span class="delimiter">&quot;</span><span class="content">Tell me a {adjective} joke about {topic}</span><span class="delimiter">&quot;</span></span>);

Prompt prompt = promptTemplate.create(<span class="predefined-type">Map</span>.of(<span class="string"><span class="delimiter">&quot;</span><span class="content">adjective</span><span class="delimiter">&quot;</span></span>, adjective, <span class="string"><span class="delimiter">&quot;</span><span class="content">topic</span><span class="delimiter">&quot;</span></span>, topic));

<span class="keyword">return</span> chatClient.call(prompt).getResult();</code></pre>
</div>
</div>
<div class="paragraph">
<p>En este ejemplo, se crea un <code>PromptTemplate</code> con una plantilla de prompt que incluye marcadores de posición para un adjetivo y un tema. Luego, se crea un <code>Prompt</code> a partir de la plantilla con valores específicos para el adjetivo y el tema. Finalmente, se envía el <code>Prompt</code> al modelo de IA para obtener una respuesta.</p>
</div>
<div class="listingblock">
<div class="title">Otro ejemplo de uso de PromptTemplate:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">String</span> userText = <span class="string"><span class="delimiter">&quot;</span><span class="delimiter">&quot;</span></span><span class="string"><span class="delimiter">&quot;</span><span class="content">
    Tell me about three famous pirates from the Golden Age of Piracy and why they did.
    Write at least a sentence for each pirate.
    </span><span class="delimiter">&quot;</span></span><span class="string"><span class="delimiter">&quot;</span><span class="delimiter">&quot;</span></span>;

Message userMessage = <span class="keyword">new</span> UserMessage(userText);

<span class="predefined-type">String</span> systemText = <span class="string"><span class="delimiter">&quot;</span><span class="delimiter">&quot;</span></span><span class="string"><span class="delimiter">&quot;</span><span class="content">
  You are a helpful AI assistant that helps people find information.
  Your name is {name}
  You should reply to the user's request with your name and also in the style of a {voice}.
  </span><span class="delimiter">&quot;</span></span><span class="string"><span class="delimiter">&quot;</span><span class="delimiter">&quot;</span></span>;

SystemPromptTemplate systemPromptTemplate = <span class="keyword">new</span> SystemPromptTemplate(systemText);
Message systemMessage = systemPromptTemplate.createMessage(<span class="predefined-type">Map</span>.of(<span class="string"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>, name, <span class="string"><span class="delimiter">&quot;</span><span class="content">voice</span><span class="delimiter">&quot;</span></span>, voice));

Prompt prompt = <span class="keyword">new</span> Prompt(<span class="predefined-type">List</span>.of(userMessage, systemMessage));

<span class="predefined-type">List</span>&lt;Generation&gt; response = chatClient.call(prompt).getResults();</code></pre>
</div>
</div>
<div class="paragraph">
<p>En este ejemplo, se crea un mensaje de usuario con una solicitud de información sobre piratas. Luego, se crea un mensaje del sistema con una plantilla que incluye marcadores de posición para el nombre y la voz del asistente de IA. Se crea un <code>Prompt</code> con los mensajes de usuario y sistema, y se envía al modelo de IA para obtener una respuesta.</p>
</div>
<div class="paragraph">
<p>El interfaz OutputParser permite obtener una salida estructurada, por ejemplo, mapeando la salida a una clase Java o a un array de valores a partir de la salida basada en cadenas de los modelos de IA.</p>
</div>
<div class="listingblock">
<div class="title">EL interfaz OutputParser es:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">interface</span> <span class="class">OutputParser</span>&lt;T&gt; <span class="directive">extends</span> <span class="predefined-type">Parser</span>&lt;T&gt;, FormatProvider {
   T parse(<span class="predefined-type">String</span> text);
        <span class="predefined-type">String</span> getFormat();
}</code></pre>
</div>
</div>
<div class="ulist">
<div class="title">El interfaz OutputParser tiene las siguientes implementaciones disponibles:</div>
<ul>
<li>
<p><strong>BeanOutputParser:</strong> Especifica el esquema JSON para la clase Java y utiliza DRAFT_2020_12 de la especificación del esquema JSON, ya que OpenAI ha indicado que esto daría los mejores resultados. La salida JSON del modelo de IA se deserializa a un objeto Java, también conocido como JavaBean.</p>
</li>
<li>
<p><strong>MapOutputParser:</strong> Similar a BeanOutputParser, pero la carga útil JSON se deserializa en una instancia de java.util.Map&lt;String, Object&gt;.</p>
</li>
<li>
<p><strong>ListOutputParser:</strong> Especifica que la salida sea una lista delimitada por comas.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Ejemplo de uso de OutputParser:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="type">class</span> <span class="class">ActorsFilms</span> {

        <span class="directive">public</span> <span class="predefined-type">String</span> actor;

        <span class="directive">public</span> <span class="predefined-type">List</span>&lt;<span class="predefined-type">String</span>&gt; movies;

    <span class="comment">// getters and toString omitted</span>
}

<span class="annotation">@GetMapping</span>(<span class="string"><span class="delimiter">&quot;</span><span class="content">/ai/output</span><span class="delimiter">&quot;</span></span>)
    <span class="directive">public</span> ActorsFilms generate(<span class="annotation">@RequestParam</span>(value = <span class="string"><span class="delimiter">&quot;</span><span class="content">actor</span><span class="delimiter">&quot;</span></span>, defaultValue = <span class="string"><span class="delimiter">&quot;</span><span class="content">Jeff Bridges</span><span class="delimiter">&quot;</span></span>) <span class="predefined-type">String</span> actor) {
        <span class="type">var</span> outputParser = <span class="keyword">new</span> BeanOutputParser&lt;&gt;(ActorsFilms.class);

        <span class="predefined-type">String</span> userMessage =
                <span class="string"><span class="delimiter">&quot;</span><span class="delimiter">&quot;</span></span><span class="string"><span class="delimiter">&quot;</span><span class="content">
                Generate the filmography for the actor {actor}.
                {format}
                </span><span class="delimiter">&quot;</span></span><span class="string"><span class="delimiter">&quot;</span><span class="delimiter">&quot;</span></span>;

        PromptTemplate promptTemplate = <span class="keyword">new</span> PromptTemplate(userMessage, <span class="predefined-type">Map</span>.of(<span class="string"><span class="delimiter">&quot;</span><span class="content">actor</span><span class="delimiter">&quot;</span></span>, actor, <span class="string"><span class="delimiter">&quot;</span><span class="content">format</span><span class="delimiter">&quot;</span></span>, outputParser.getFormat() ));
        Prompt prompt = promptTemplate.create();
        Generation generation = chatClient.call(prompt).getResult();

        ActorsFilms actorsFilms = outputParser.parse(generation.getOutput().getContent());
        <span class="keyword">return</span> actorsFilms;
    }</code></pre>
</div>
</div>
<div class="sect4">
<h5 id="_openai_chat_completion">OpenAI Chat Completion</h5>
<div class="paragraph">
<p>El OpenAI Chat Completion es un servicio de inteligencia artificial que permite a los desarrolladores integrar capacidades de chat en sus aplicaciones y sistemas. Utiliza el modelo de lenguaje GPT-3 de OpenAI para generar respuestas coherentes y relevantes en función de las entradas de texto proporcionadas.</p>
</div>
<div class="listingblock">
<div class="title">Instalación con Maven:</div>
<div class="content">
<pre>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.ai&lt;/groupId&gt;
    &lt;artifactId&gt;spring-ai-openai-spring-boot-starter&lt;/artifactId&gt;
&lt;/dependency&gt;</pre>
</div>
</div>
<div class="listingblock">
<div class="title">Instalación con Gradle:</div>
<div class="content">
<pre>dependencies {
    implementation 'org.springframework.ai:spring-ai-openai-spring-boot-starter'
}</pre>
</div>
</div>
<div class="ulist">
<div class="title">En OpenAI Chat Completion, las propiedades de chat se dividen en:</div>
<ul>
<li>
<p><strong>retry properties</strong>: Propiedades de reintentos</p>
</li>
<li>
<p><strong>connection properties</strong>: Propiedades de conexión</p>
</li>
<li>
<p><strong>configuration properties</strong>: Propiedades de configuración</p>
</li>
</ul>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 3. Las propiedades de reintentos son:</caption>
<colgroup>
<col style="width: 20%;">
<col style="width: 60%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Propiedad</th>
<th class="tableblock halign-left valign-top">Descripción</th>
<th class="tableblock halign-left valign-top">Predeterminado</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.retry.max-attempts</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Número máximo de intentos de reintento.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">10</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.retry.backoff.initial-interval</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Duración inicial de espera para la política de retroceso exponencial.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2 seg.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.retry.backoff.multiplier</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Multiplicador del intervalo de retroceso.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">5</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.retry.backoff.max-interval</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Duración máxima de retroceso.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3 min.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.retry.on-client-errors</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Si es falso, lanza una NonTransientAiException y no intente reintentar para los códigos de error 4xx del cliente.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.retry.exclude-on-http-codes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Lista de códigos de estado HTTP que no deben desencadenar un reintento (por ejemplo, para lanzar NonTransientAiException).</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">vacío</p></td>
</tr>
</tbody>
</table>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 4. Las propiedades de conexión son:</caption>
<colgroup>
<col style="width: 20%;">
<col style="width: 60%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Propiedad</th>
<th class="tableblock halign-left valign-top">Descripción</th>
<th class="tableblock halign-left valign-top">Predeterminado</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.base-url</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">La URL para conectarse.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">api.openai.com</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.api-key</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">La clave API.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
</tbody>
</table>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 5. Las propiedades de configuración son:</caption>
<colgroup>
<col style="width: 20%;">
<col style="width: 60%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Propiedad</th>
<th class="tableblock halign-left valign-top">Descripción</th>
<th class="tableblock halign-left valign-top">Predeterminado</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.chat.enabled</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Habilitar el cliente de chat de OpenAI.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">true</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.chat.base-url</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Opcional, sobrescribe la spring.ai.openai.base-url para proporcionar una URL específica para el chat.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.chat.api-key</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Opcional, sobrescribe la spring.ai.openai.api-key para proporcionar una clave API específica para el chat.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.chat.options.model</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Este es el modelo de chat de OpenAI a utilizar.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">gpt-3.5-turbo (los gpt-3.5-turbo, gpt-4 y gpt-4-32k apuntan a las versiones más recientes del modelo)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.chat.options.temperature</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">La temperatura de muestreo a utilizar que controla la creatividad aparente de las respuestas generadas. Valores más altos harán que la salida sea más aleatoria mientras que valores más bajos harán que los resultados sean más enfocados y deterministas. No se recomienda modificar temperature y top_p para la misma solicitud de completación, ya que la interacción de estos dos ajustes es difícil de predecir.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.8</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.chat.options.frequencyPenalty</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Número entre -2.0 y 2.0. Valores positivos penalizan nuevos tokens basados en su frecuencia existente en el texto hasta ahora, disminuyendo la probabilidad de que el modelo repita la misma línea textualmente.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0f</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.chat.options.logitBias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Modifica la probabilidad de que aparezcan tokens específicos en la completación.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.chat.options.maxTokens</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">El número máximo de tokens a generar en la completación del chat. La longitud total de los tokens de entrada y los tokens generados está limitada por la longitud del contexto del modelo.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.chat.options.n</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cuántas opciones de completación de chat generar para cada mensaje de entrada. Tenga en cuenta que se le cobrará según el número de tokens generados en todas las opciones. Mantenga n en 1 para minimizar costos.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.chat.options.presencePenalty</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Número entre -2.0 y 2.0. Valores positivos penalizan nuevos tokens basados en si aparecen en el texto hasta ahora, aumentando la probabilidad de que el modelo hable sobre nuevos temas.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.chat.options.responseFormat</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Un objeto que especifica el formato que el modelo debe generar. Establecer en { "type": "json_object" } habilita el modo JSON, que garantiza que el mensaje que genera el modelo sea JSON válido.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.chat.options.seed</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Esta función está en Beta. Si se especifica, nuestro sistema hará el mejor esfuerzo para muestrear de manera determinista, de modo que las solicitudes repetidas con la misma semilla y parámetros deberían devolver el mismo resultado.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.chat.options.stop</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Hasta 4 secuencias donde la API dejará de generar más tokens.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.chat.options.topP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Una alternativa al muestreo con temperatura, llamada muestreo de núcleo, donde el modelo considera los resultados de los tokens con masa de probabilidad top_p. Así, 0.1 significa que solo se consideran los tokens que comprenden el 10% superior de la masa de probabilidad. Generalmente recomendamos alterar esto o la temperatura, pero no ambos.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.chat.options.tools</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Una lista de herramientas que el modelo puede llamar. Actualmente, solo se admiten funciones como herramientas. Utilice esto para proporcionar una lista de funciones para las cuales el modelo puede generar entradas JSON.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.chat.options.toolChoice</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Controla cuál (si hay alguna) función es llamada por el modelo. none significa que el modelo no llamará a ninguna función y en su lugar generará un mensaje. auto significa que el modelo puede elegir entre generar un mensaje o llamar a una función. Especificar una función particular mediante {"type: "function", "function": {"name": "my_function"}} obliga al modelo a llamar a esa función. none es el valor predeterminado cuando no hay funciones presentes. auto es el valor predeterminado si hay funciones presentes.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.chat.options.user</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Un identificador único que representa a su usuario final, lo que puede ayudar a OpenAI a monitorear y detectar abusos.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.chat.options.functions</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Lista de funciones, identificadas por sus nombres, para habilitar la llamada de funciones en una sola solicitud de prompt. Las funciones con esos nombres deben existir en el registro functionCallbacks.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
</tbody>
</table>
<div class="sect5">
<h6 id="_ejemplos_de_uso_de_openai_chat_completion">Ejemplos de uso de OpenAI Chat Completion</h6>
<div class="paragraph">
<p>Para usar el servicio de Chat Completion de OpenAI en Spring AI, primero necesitas configurar las propiedades de conexión y configuración en tu archivo <code>application.properties</code>.</p>
</div>
<div class="listingblock">
<div class="title">A continuución, se muestra un ejemplo de cómo podría quedar application.properties:</div>
<div class="content">
<pre class="CodeRay highlight"><code>spring.ai.openai.api-key=YOUR_API_KEY
spring.ai.openai.chat.options.model=gpt-3.5-turbo
spring.ai.openai.chat.options.temperature=0.7</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">El controlador de Spring Boot para el servicio de Chat Completion de OpenAI podría ser así:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="annotation">@RestController</span>
<span class="directive">public</span> <span class="type">class</span> <span class="class">ChatController</span> {

    <span class="directive">private</span> <span class="directive">final</span> OpenAiChatClient chatClient;

    <span class="annotation">@Autowired</span>
    <span class="directive">public</span> ChatController(OpenAiChatClient chatClient) {
        <span class="local-variable">this</span>.chatClient = chatClient;
    }

    <span class="annotation">@GetMapping</span>(<span class="string"><span class="delimiter">&quot;</span><span class="content">/ai/generate</span><span class="delimiter">&quot;</span></span>)
    <span class="directive">public</span> <span class="predefined-type">Map</span> generate(<span class="annotation">@RequestParam</span>(value = <span class="string"><span class="delimiter">&quot;</span><span class="content">message</span><span class="delimiter">&quot;</span></span>, defaultValue = <span class="string"><span class="delimiter">&quot;</span><span class="content">Tell me a joke</span><span class="delimiter">&quot;</span></span>) <span class="predefined-type">String</span> message) {
        <span class="keyword">return</span> <span class="predefined-type">Map</span>.of(<span class="string"><span class="delimiter">&quot;</span><span class="content">generation</span><span class="delimiter">&quot;</span></span>, chatClient.call(message));
    }

    <span class="annotation">@GetMapping</span>(<span class="string"><span class="delimiter">&quot;</span><span class="content">/ai/generateStream</span><span class="delimiter">&quot;</span></span>)
        <span class="directive">public</span> Flux&lt;ChatResponse&gt; generateStream(<span class="annotation">@RequestParam</span>(value = <span class="string"><span class="delimiter">&quot;</span><span class="content">message</span><span class="delimiter">&quot;</span></span>, defaultValue = <span class="string"><span class="delimiter">&quot;</span><span class="content">Tell me a joke</span><span class="delimiter">&quot;</span></span>) <span class="predefined-type">String</span> message) {
        Prompt prompt = <span class="keyword">new</span> Prompt(<span class="keyword">new</span> UserMessage(message));
        <span class="keyword">return</span> chatClient.stream(prompt);
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>En este controlador, se inyecta un <code>OpenAiChatClient</code> y se define un método <code>generate</code> que toma un mensaje de texto y llama al cliente de chat para generar una respuesta. También se define un método <code>generateStream</code> que toma un mensaje de texto y llama al cliente de chat para generar una respuesta en tiempo real utilizando un <code>Flux</code>.</p>
</div>
<div class="listingblock">
<div class="title">Podemos añadir la dependencia de OpenAI al proyecto de Spring AI con Maven:</div>
<div class="content">
<pre class="CodeRay highlight"><code>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.ai&lt;/groupId&gt;
    &lt;artifactId&gt;spring-ai-openai&lt;/artifactId&gt;
&lt;/dependency&gt;</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">O con Gradle:</div>
<div class="content">
<pre>dependencies {
    implementation 'org.springframework.ai:spring-ai-openai'
}</pre>
</div>
</div>
<div class="listingblock">
<div class="title">A partir de aquí, podemos configurar el uso del modelo de OpenAI en nuestro proyecto de Spring AI.</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">openAiApi = <span class="keyword">new</span> OpenAiApi(<span class="predefined-type">System</span>.getenv(<span class="string"><span class="delimiter">&quot;</span><span class="content">OPENAI_API_KEY</span><span class="delimiter">&quot;</span></span>));

chatClient = <span class="keyword">new</span> OpenAiChatClient(openAiApi)
    .withDefaultOptions(OpenAiChatOptions.builder()
            .withModel(<span class="string"><span class="delimiter">&quot;</span><span class="content">gpt-35-turbo</span><span class="delimiter">&quot;</span></span>)
            .withTemperature(<span class="float">0.4</span>)
            .withMaxTokens(<span class="integer">200</span>)
        .build());

ChatResponse response = chatClient.call(
    <span class="keyword">new</span> Prompt(<span class="string"><span class="delimiter">&quot;</span><span class="content">Generate the names of 5 famous pirates.</span><span class="delimiter">&quot;</span></span>));

<span class="comment">// Or with streaming responses</span>
Flux&lt;ChatResponse&gt; response = chatClient.stream(
    <span class="keyword">new</span> Prompt(<span class="string"><span class="delimiter">&quot;</span><span class="content">Generate the names of 5 famous pirates.</span><span class="delimiter">&quot;</span></span>));</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="_llamadas_a_funciones_con_openaichatclient">Llamadas a funciones con OpenAIChatClient</h6>
<div class="paragraph">
<p>Se puede registrar funciones Java personalizadas con el OpenAiChatClient y hacer que el modelo de OpenAI elija inteligentemente generar un objeto JSON que contenga argumentos para llamar a una o muchas de las funciones registradas. Esto te permite conectar las capacidades de LLM con herramientas y APIs externas. Los modelos de OpenAI están entrenados para detectar cuándo se debe llamar a una función y responder con JSON que se ajusta a la firma de la función.</p>
</div>
<div class="paragraph">
<p>Spring AI proporciona mecanismos flexibles y fáciles de usar para registrar y llamar a funciones personalizadas. En general, las funciones personalizadas deben proporcionar un nombre de función, una descripción y la firma de la llamada a la función (como esquema JSON) para que el modelo sepa qué argumentos espera la función. La descripción ayuda al modelo a entender cuándo llamar a la función.</p>
</div>
<div class="listingblock">
<div class="title">Partimos de una clase que define un objeto de información meteorológica:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">class</span> <span class="class">MockWeatherService</span> <span class="directive">implements</span> Function&lt;Request, Response&gt; {

        <span class="directive">public</span> <span class="type">enum</span> Unit { C, F }
        <span class="directive">public</span> record Request(<span class="predefined-type">String</span> location, Unit unit) {}
        <span class="directive">public</span> record Response(<span class="type">double</span> temp, Unit unit) {}

        <span class="directive">public</span> Response apply(Request request) {
                <span class="keyword">return</span> <span class="keyword">new</span> Response(<span class="float">30.0</span>, Unit.C);
        }
}</code></pre>
</div>
</div>
<div class="olist arabic">
<div class="title">Hay dos formas de registrar funciones con el OpenAiChatClient como Beans de Spring:</div>
<ol class="arabic">
<li>
<p><strong>Funciones Java planas</strong></p>
</li>
<li>
<p><strong> Wrapper de FunctionCallback</strong></p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Internamente, Spring AI ChatClient creará una instancia wrapper FunctionCallbackWrapper que añade la lógica para que sea invocado a través del modelo de IA. El nombre del @Bean se pasa como ChatOption.</p>
</div>
<div class="listingblock">
<div class="title">Un ejemplo de cómo registrar una función Java plana:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="annotation">@Configuration</span>
<span class="directive">static</span> <span class="type">class</span> <span class="class">Config</span> {

        <span class="annotation">@Bean</span>
        <span class="annotation">@Description</span>(<span class="string"><span class="delimiter">&quot;</span><span class="content">Get the weather in location</span><span class="delimiter">&quot;</span></span>) <span class="comment">// function description</span>
        <span class="directive">public</span> Function&lt;MockWeatherService.Request, MockWeatherService.Response&gt; weatherFunction1() {
                <span class="keyword">return</span> <span class="keyword">new</span> MockWeatherService();
        }
        ...
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>La anotación @Description es opcional y proporciona una descripción de la función que ayuda al modelo a entender cuándo llamar a la función. Es una propiedad importante para establecer para ayudar al modelo de IA a determinar qué función del lado del cliente invocar.</p>
</div>
<div class="listingblock">
<div class="title">Un ejemplo de cómo registrar una función con un wrapper de FunctionCallback:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="annotation">@Configuration</span>
<span class="directive">static</span> <span class="type">class</span> <span class="class">Config</span> {

        <span class="annotation">@Bean</span>
        <span class="directive">public</span> FunctionCallback weatherFunctionInfo() {

                <span class="keyword">return</span> <span class="keyword">new</span> FunctionCallbackWrapper&lt;&gt;(<span class="string"><span class="delimiter">&quot;</span><span class="content">CurrentWeather</span><span class="delimiter">&quot;</span></span>, <span class="comment">// (1) function name</span>
                                <span class="string"><span class="delimiter">&quot;</span><span class="content">Get the weather in location</span><span class="delimiter">&quot;</span></span>, <span class="comment">// (2) function description</span>
                                (response) -&gt; <span class="string"><span class="delimiter">&quot;</span><span class="delimiter">&quot;</span></span> + response.temp() + response.unit(), <span class="comment">// (3) Response Converter</span>
                                <span class="keyword">new</span> MockWeatherService()); <span class="comment">// function code</span>
        }
        ...
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Esto encapsula la función de terceros, MockWeatherService, y la registra como una función CurrentWeather con el OpenAiChatClient. También proporciona una descripción (2) y un convertidor de respuesta opcional (3) para convertir la respuesta en un texto como se espera por el modelo.</p>
</div>
<div class="paragraph">
<p>Por defecto, el convertidor de respuesta hace una serialización JSON del objeto de respuesta.</p>
</div>
<div class="listingblock">
<div class="title">Especificación de esta función en el objeto ChatOptions:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">OpenAiChatClient chatClient = ...

UserMessage userMessage = <span class="keyword">new</span> UserMessage(<span class="string"><span class="delimiter">&quot;</span><span class="content">What's the weather like in San Francisco, Tokyo, and Paris?</span><span class="delimiter">&quot;</span></span>);

ChatResponse response = chatClient.call(<span class="keyword">new</span> Prompt(<span class="predefined-type">List</span>.of(userMessage),
                OpenAiChatOptions.builder().withFunction(<span class="string"><span class="delimiter">&quot;</span><span class="content">CurrentWeather</span><span class="delimiter">&quot;</span></span>).build()));

logger.info(<span class="string"><span class="delimiter">&quot;</span><span class="content">Response: {}</span><span class="delimiter">&quot;</span></span>, response);</code></pre>
</div>
</div>
<div class="paragraph">
<p>En este ejemplo, se envía un mensaje de usuario que contiene una pregunta sobre el clima en varias ubicaciones. Se habilita la función CurrentWeather en las opciones de chat (1), lo que indica al modelo de IA que llame a la función registrada para obtener la información meteorológica.</p>
</div>
<div class="listingblock">
<div class="title">La respuesta final tendrá el siguiente formato:</div>
<div class="content">
<pre class="CodeRay highlight"><code>Here is the current weather for the requested cities:
- San Francisco, CA: 30.0°C
- Tokyo, Japan: 10.0°C
- Paris, France: 15.0°C</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Además de la autoconfiguración, puedes registrar funciones de devolución de llamada, dinámicamente, con tus solicitudes de Prompt:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">OpenAiChatClient chatClient = ...

UserMessage userMessage = <span class="keyword">new</span> UserMessage(<span class="string"><span class="delimiter">&quot;</span><span class="content">What's the weather like in San Francisco, Tokyo, and Paris?</span><span class="delimiter">&quot;</span></span>);

<span class="type">var</span> promptOptions = OpenAiChatOptions.builder()
        .withFunctionCallbacks(<span class="predefined-type">List</span>.of(<span class="keyword">new</span> FunctionCallbackWrapper&lt;&gt;(
                <span class="string"><span class="delimiter">&quot;</span><span class="content">CurrentWeather</span><span class="delimiter">&quot;</span></span>, <span class="comment">// name</span>
                <span class="string"><span class="delimiter">&quot;</span><span class="content">Get the weather in location</span><span class="delimiter">&quot;</span></span>, <span class="comment">// function description</span>
                <span class="keyword">new</span> MockWeatherService()))) <span class="comment">// function code</span>
        .build();

ChatResponse response = chatClient.call(<span class="keyword">new</span> Prompt(<span class="predefined-type">List</span>.of(userMessage), promptOptions));</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_embedings_api">5.3.2. Embedings API</h4>
<div class="paragraph">
<p>El interfaz EmbeddingClient está diseñado para una integración sencilla con modelos de embeddings en IA y aprendizaje automático. <strong>Su función principal es convertir texto en vectores numéricos</strong>, comúnmente conocidos como embeddings. Estos embeddings son cruciales para diversas tareas como análisis semántico y clasificación de texto.</p>
</div>
<div class="olist arabic">
<div class="title">Conceptos Clave de los Embeddings</div>
<ol class="arabic">
<li>
<p><strong>Vectorización de Datos:</strong></p>
<div class="ulist">
<ul>
<li>
<p>Los embeddings convierten datos textuales en vectores numéricos. Por ejemplo, una palabra puede ser representada como un vector de números en un espacio de alta dimensionalidad.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Captura de Semántica:</strong></p>
<div class="ulist">
<ul>
<li>
<p>Los embeddings están diseñados para capturar el significado y la relación semántica entre las palabras. Por ejemplo, en un buen espacio de embeddings, las palabras "rey" y "reina" estarán cerca una de otra y también mostrarán relaciones como "hombre" a "mujer".</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Contexto:</strong></p>
<div class="ulist">
<ul>
<li>
<p>Los embeddings contextuales, como los generados por modelos como BERT y GPT, tienen en cuenta el contexto en el que una palabra aparece, lo que permite desambiguar palabras con múltiples significados según el contexto.</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="olist arabic">
<div class="title">Tipos de Embeddings</div>
<ol class="arabic">
<li>
<p><strong>Word Embeddings:</strong></p>
<div class="ulist">
<ul>
<li>
<p>Representan palabras individuales como vectores en un espacio vectorial. Ejemplos populares incluyen Word2Vec, GloVe y FastText.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Contextual Embeddings:</strong></p>
<div class="ulist">
<ul>
<li>
<p>Generados por modelos que tienen en cuenta el contexto en el que una palabra aparece. Modelos como BERT, GPT y ELMo producen embeddings diferentes para una misma palabra según su contexto en la oración.</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="olist arabic">
<div class="title">Ejemplos de Uso de Embeddings</div>
<ol class="arabic">
<li>
<p><strong>Clasificación de Texto:</strong></p>
<div class="ulist">
<ul>
<li>
<p>Los embeddings pueden ser utilizados como características de entrada para modelos de clasificación de texto, ayudando a agrupar y categorizar documentos basados en su contenido.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Búsqueda y Recuperación de Información:</strong></p>
<div class="ulist">
<ul>
<li>
<p>Al convertir consultas y documentos en embeddings, se puede medir la similitud entre ellos y recuperar los documentos más relevantes para una consulta.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Análisis de Sentimientos:</strong></p>
<div class="ulist">
<ul>
<li>
<p>Los embeddings permiten capturar las sutilezas de los sentimientos expresados en el texto, mejorando la precisión de los modelos de análisis de sentimientos.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Traducción Automática:</strong></p>
<div class="ulist">
<ul>
<li>
<p>En los sistemas de traducción, los embeddings ayudan a mapear palabras y frases entre diferentes idiomas, facilitando una traducción más precisa y natural.</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>Los embeddings son representaciones vectoriales densas que capturan la semántica de los datos textuales. Para determinar similitudes de conceptos utilizando embeddings, se pueden realizar varias operaciones matemáticas y estadísticas. A continuación se describen algunas de las más comunes:</p>
</div>
<div class="olist arabic">
<div class="title">Operaciones Comunes con Embeddings</div>
<ol class="arabic">
<li>
<p><strong>Producto vectorial (Dot Product):</strong></p>
<div class="ulist">
<ul>
<li>
<p>El producto vectorial entre dos vectores embeddings puede ser utilizado para medir la similitud. Un valor mayor indica una mayor similitud.
[source,python]
----
similitud = np.dot(embedding1, embedding2)
----</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Distancia Euclidiana (Euclidean Distance):</strong></p>
<div class="ulist">
<ul>
<li>
<p>La distancia euclidiana mide la distancia "recta" entre dos puntos en el espacio de embeddings. Valores más pequeños indican mayor similitud.
[source,python]
----
distancia = np.linalg.norm(embedding1 - embedding2)
----</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Similitud del Coseno (Cosine Similarity):</strong></p>
<div class="ulist">
<ul>
<li>
<p>La similitud del coseno mide el coseno del ángulo entre dos vectores. Es un valor entre -1 y 1, donde 1 indica vectores idénticos en dirección.
[source,python]
----
from sklearn.metrics.pairwise import cosine_similarity
similitud = cosine_similarity([embedding1], [embedding2])
----</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="olist arabic">
<div class="title">Operaciones Avanzadas con Embeddings</div>
<ol class="arabic">
<li>
<p><strong>Distancia de Manhattan (Manhattan Distance):</strong></p>
<div class="ulist">
<ul>
<li>
<p>También conocida como distancia L1, es la suma de las diferencias absolutas de sus componentes. Es útil en ciertos contextos donde las diferencias lineales son más importantes.
[source,python]
----
distancia = np.sum(np.abs(embedding1 - embedding2))
----</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Distancia de Chebyshev (Chebyshev Distance):</strong></p>
<div class="ulist">
<ul>
<li>
<p>Esta medida de distancia toma el valor máximo de las diferencias absolutas de sus componentes. Es útil en aplicaciones donde se debe considerar la máxima diferencia en cualquier dimensión.
[source,python]
----
distancia = np.max(np.abs(embedding1 - embedding2))
----</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Similitud de Jaccard (Jaccard Similarity):</strong></p>
<div class="ulist">
<ul>
<li>
<p>Aunque más comúnmente utilizada para conjuntos, la similitud de Jaccard puede ser adaptada para vectores esparcidos o binarios.
[source,python]
----
interseccion = np.minimum(embedding1, embedding2).sum()
union = np.maximum(embedding1, embedding2).sum()
similitud = interseccion / union
----</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="olist arabic">
<div class="title">Aplicaciones de Similitud de Embeddings</div>
<ol class="arabic">
<li>
<p><strong>Agrupación de Documentos (Document Clustering):</strong></p>
<div class="ulist">
<ul>
<li>
<p>Utilizando medidas de similitud para agrupar documentos similares en grupos (clusters).</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Recuperación de Información (Information Retrieval):</strong></p>
<div class="ulist">
<ul>
<li>
<p>Comparar consultas con documentos para encontrar los más relevantes basados en la similitud de sus embeddings.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Detección de Duplicados (Duplicate Detection):</strong></p>
<div class="ulist">
<ul>
<li>
<p>Identificar documentos o registros duplicados mediante la comparación de sus embeddings.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Análisis de Sentimientos (Sentiment Analysis):</strong></p>
<div class="ulist">
<ul>
<li>
<p>Evaluar la similitud entre frases para determinar sentimientos similares o diferentes.</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>En resumen, los embeddings permiten realizar una variedad de operaciones matemáticas para determinar la similitud entre conceptos, facilitando tareas como la agrupación, la recuperación de información y la detección de duplicados.</p>
</div>
<div class="listingblock">
<div class="title">Consideremos un modelo simple de Word2Vec. Aquí, palabras como "rey" y "reina" pueden tener embeddings que capturan la relación entre géneros. Si <code>v(rey)</code> representa el embedding de "rey" y <code>v(hombre)</code> representa el embedding de "hombre", entonces la relación <code>v(rey) - v(hombre) + v(mujer)</code> debería resultar en un vector cercano a <code>v(reina)</code>.</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="comment"># Ejemplo ilustrativo de cómo podría verse en un espacio de embeddings</span>
v_rey = model[<span class="string"><span class="delimiter">'</span><span class="content">rey</span><span class="delimiter">'</span></span>]
v_reina = model[<span class="string"><span class="delimiter">'</span><span class="content">reina</span><span class="delimiter">'</span></span>]
v_hombre = model[<span class="string"><span class="delimiter">'</span><span class="content">hombre</span><span class="delimiter">'</span></span>]
v_mujer = model[<span class="string"><span class="delimiter">'</span><span class="content">mujer</span><span class="delimiter">'</span></span>]

resultado = v_rey - v_hombre + v_mujer

<span class="comment"># Verificamos la similitud</span>
similitud = cosine_similarity(resultado, v_reina)</code></pre>
</div>
</div>
<div class="paragraph">
<p>En resumen, los embeddings son una herramienta fundamental en los modelos de lenguaje, ya que permiten transformar datos textuales en una forma que los modelos pueden procesar y entender, capturando las relaciones semánticas y contextuales de manera efectiva.</p>
</div>
<div class="ulist">
<div class="title">El diseño de la interfaz EmbeddingClient en Spring AI se centra en dos objetivos principales:</div>
<ul>
<li>
<p><strong>Portabilidad:</strong> Esta interfaz garantiza una fácil adaptabilidad entre varios modelos de embeddings. Permite a los desarrolladores cambiar entre diferentes técnicas o modelos de embeddings con cambios mínimos en el código.</p>
</li>
<li>
<p><strong>Simplicidad:</strong> EmbeddingClient simplifica el proceso de convertir texto en embeddings. Al proporcionar métodos directos como embed(String text) y embed(Document document), elimina la complejidad de tratar con datos de texto en bruto y algoritmos de embedding. Esta elección de diseño facilita a los desarrolladores, especialmente a los nuevos en IA, utilizar embeddings en sus aplicaciones sin profundizar en la mecánica subyacente.</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">Los elementos principales del API de embeddings son:</div>
<ul>
<li>
<p><strong>EmbeddingClient</strong></p>
</li>
<li>
<p><strong>EmbeddingRequest</strong></p>
</li>
<li>
<p><strong>EmbeddingResponse</strong></p>
</li>
<li>
<p><strong>Embedding</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">La definición de la interfaz <code>EmbeddingClient</code> es:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">interface</span> <span class="class">EmbeddingClient</span> <span class="directive">extends</span> ModelClient&lt;EmbeddingRequest, EmbeddingResponse&gt; {

        <span class="annotation">@Override</span>
        EmbeddingResponse call(EmbeddingRequest request);


        <span class="comment">/**
         * Embeds the given document's content into a vector.
         * @param document the document to embed.
         * @return the embedded vector.
         */</span>
        <span class="predefined-type">List</span>&lt;<span class="predefined-type">Double</span>&gt; embed(<span class="predefined-type">Document</span> document);

        <span class="comment">/**
         * Embeds the given text into a vector.
         * @param text the text to embed.
         * @return the embedded vector.
         */</span>
        <span class="keyword">default</span> <span class="predefined-type">List</span>&lt;<span class="predefined-type">Double</span>&gt; embed(<span class="predefined-type">String</span> text) {
                Assert.notNull(text, <span class="string"><span class="delimiter">&quot;</span><span class="content">Text must not be null</span><span class="delimiter">&quot;</span></span>);
                <span class="keyword">return</span> <span class="local-variable">this</span>.embed(<span class="predefined-type">List</span>.of(text)).iterator().next();
        }

        <span class="comment">/**
         * Embeds a batch of texts into vectors.
         * @param texts list of texts to embed.
         * @return list of list of embedded vectors.
         */</span>
        <span class="keyword">default</span> <span class="predefined-type">List</span>&lt;<span class="predefined-type">List</span>&lt;<span class="predefined-type">Double</span>&gt;&gt; embed(<span class="predefined-type">List</span>&lt;<span class="predefined-type">String</span>&gt; texts) {
                Assert.notNull(texts, <span class="string"><span class="delimiter">&quot;</span><span class="content">Texts must not be null</span><span class="delimiter">&quot;</span></span>);
                <span class="keyword">return</span> <span class="local-variable">this</span>.call(<span class="keyword">new</span> EmbeddingRequest(texts, EmbeddingOptions.EMPTY))
                        .getResults()
                        .stream()
                        .map(Embedding::getOutput)
                        .toList();
        }

        <span class="comment">/**
         * Embeds a batch of texts into vectors and returns the {@link EmbeddingResponse}.
         * @param texts list of texts to embed.
         * @return the embedding response.
         */</span>
        <span class="keyword">default</span> EmbeddingResponse embedForResponse(<span class="predefined-type">List</span>&lt;<span class="predefined-type">String</span>&gt; texts) {
                Assert.notNull(texts, <span class="string"><span class="delimiter">&quot;</span><span class="content">Texts must not be null</span><span class="delimiter">&quot;</span></span>);
                <span class="keyword">return</span> <span class="local-variable">this</span>.call(<span class="keyword">new</span> EmbeddingRequest(texts, EmbeddingOptions.EMPTY));
        }

        <span class="comment">/**
         * @return the number of dimensions of the embedded vectors. It is generative
         * specific.
         */</span>
        <span class="keyword">default</span> <span class="type">int</span> dimensions() {
                <span class="keyword">return</span> embed(<span class="string"><span class="delimiter">&quot;</span><span class="content">Test String</span><span class="delimiter">&quot;</span></span>).size();
        }

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Donde <code>EmbeddingRequest</code> es la entrada al modelo de embeddings y <code>EmbeddingResponse</code> es la salida generada por el modelo. La interfaz <code>EmbeddingClient</code> define métodos para incrustar documentos y textos en vectores, así como para obtener la dimensión de los vectores incrustados.</p>
</div>
<div class="listingblock">
<div class="title">La definición de la clase <code>EmbeddingRequest</code> es:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">class</span> <span class="class">EmbeddingRequest</span> <span class="directive">implements</span> ModelRequest&lt;<span class="predefined-type">List</span>&lt;<span class="predefined-type">String</span>&gt;&gt; {
        <span class="directive">private</span> <span class="directive">final</span> <span class="predefined-type">List</span>&lt;<span class="predefined-type">String</span>&gt; inputs;
        <span class="directive">private</span> <span class="directive">final</span> EmbeddingOptions options;
        <span class="comment">// other methods omitted</span>
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Donde <code>EmbeddingOptions</code> son las opciones de configuración del modelo de embeddings. La clase <code>EmbeddingRequest</code> implementa la interfaz <code>ModelRequest</code> y proporciona métodos para acceder a los textos de entrada y opciones de configuración.</p>
</div>
<div class="listingblock">
<div class="title">La definición de la clase <code>EmbeddingResponse</code> es:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">class</span> <span class="class">EmbeddingResponse</span> <span class="directive">implements</span> ModelResponse&lt;Embedding&gt; {

        <span class="directive">private</span> <span class="predefined-type">List</span>&lt;Embedding&gt; embeddings;
        <span class="directive">private</span> EmbeddingResponseMetadata metadata = <span class="keyword">new</span> EmbeddingResponseMetadata();
        <span class="comment">// other methods omitted</span>
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Donde <code>Embedding</code> es un vector generado por el modelo de embeddings y <code>EmbeddingResponseMetadata</code> son metadatos asociados con la respuesta de embeddings. La clase <code>EmbeddingResponse</code> implementa la interfaz <code>ModelResponse</code> y proporciona métodos para acceder a los embeddings y metadatos generados.</p>
</div>
<div class="listingblock">
<div class="title">La definición de la clase <code>Embedding</code> es:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">class</span> <span class="class">Embedding</span> <span class="directive">implements</span> ModelResult&lt;<span class="predefined-type">List</span>&lt;<span class="predefined-type">Double</span>&gt;&gt; {
        <span class="directive">private</span> <span class="predefined-type">List</span>&lt;<span class="predefined-type">Double</span>&gt; embedding;
        <span class="directive">private</span> <span class="predefined-type">Integer</span> index;
        <span class="directive">private</span> EmbeddingResultMetadata metadata;
        <span class="comment">// other methods omitted</span>
}</code></pre>
</div>
</div>
<div class="sect4">
<h5 id="_embedings_api_en_openai">Embedings API en OpenAI</h5>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 6. Reintentos de OpenAI Embeddings</caption>
<colgroup>
<col style="width: 28.5714%;">
<col style="width: 42.8571%;">
<col style="width: 28.5715%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Propiedad</th>
<th class="tableblock halign-left valign-top">Descripción</th>
<th class="tableblock halign-left valign-top">Predeterminado</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.retry.max-attempts</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Número máximo de intentos de reintento.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">10</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.retry.backoff.initial-interval</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Duración inicial de la pausa para la política de retroceso exponencial.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2 seg.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.retry.backoff.multiplier</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Multiplicador del intervalo de retroceso.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">5</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.retry.backoff.max-interval</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Duración máxima del retroceso.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3 min.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.retry.on-client-errors</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Si es false, lanza una NonTransientAiException y no intenta reintentos para los códigos de error 4xx del cliente.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.retry.exclude-on-http-codes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Lista de códigos de estado HTTP que no deben activar un reintento (por ejemplo, para lanzar NonTransientAiException).</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">vacío</p></td>
</tr>
</tbody>
</table>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 7. Propiedades de conexión de OpenAI Embeddings</caption>
<colgroup>
<col style="width: 28.5714%;">
<col style="width: 42.8571%;">
<col style="width: 28.5715%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Propiedad</th>
<th class="tableblock halign-left valign-top">Descripción</th>
<th class="tableblock halign-left valign-top">Predeterminado</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.base-url</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">La URL para conectarsespring.ai.openai.api-key=YOUR_API_KEY
spring.ai.openai.embedding.options.model=text-embedding-ada-002</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">api.openai.com</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.api-key</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">La clave API</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
</tbody>
</table>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 8. Propiedades de configuración de OpenAI Embeddings</caption>
<colgroup>
<col style="width: 28.5714%;">
<col style="width: 42.8571%;">
<col style="width: 28.5715%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Propiedad</th>
<th class="tableblock halign-left valign-top">Descripción</th>
<th class="tableblock halign-left valign-top">Predeterminado</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.embedding.enabled</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Habilitar el cliente de embeddings de OpenAI.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">true</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.embedding.base-url</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Opcional: anula la propiedad spring.ai.openai.base-url para proporcionar una URL específica para incrustaciones.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.embedding.api-key</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Opcional: anula la propiedad spring.ai.openai.api-key para proporcionar una clave API específica para incrustaciones.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.embedding.metadata-mode</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Modo de extracción de contenido del documento.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EMBED</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.embedding.options.model</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">El modelo a utilizar.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">text-embedding-ada-002 (otras opciones: text-embedding-3-large, text-embedding-3-small)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.embedding.options.encodingFormat</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">El formato para devolver las incrustaciones. Puede ser float o base64.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.embedding.options.user</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Un identificador único que representa a tu usuario final, lo que puede ayudar a OpenAI a monitorear y detectar abusos.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
</tbody>
</table>
<div class="listingblock">
<div class="title">Para usar los embeddings, es necesario configurar las propiedades de conexión y configuración en el archivo <code>application.properties</code>:</div>
<div class="content">
<pre class="CodeRay highlight"><code>spring.ai.openai.api-key=YOUR_API_KEY
spring.ai.openai.embedding.options.model=text-embedding-ada-002</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Un ejemplo de controlador de Spring Boot para el servicio de embeddings de OpenAI podría ser así:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="annotation">@RestController</span>
<span class="directive">public</span> <span class="type">class</span> <span class="class">EmbeddingController</span> {

    <span class="directive">private</span> <span class="directive">final</span> EmbeddingClient embeddingClient;

    <span class="annotation">@Autowired</span>
    <span class="directive">public</span> EmbeddingController(EmbeddingClient embeddingClient) {
        <span class="local-variable">this</span>.embeddingClient = embeddingClient;
    }

    <span class="annotation">@GetMapping</span>(<span class="string"><span class="delimiter">&quot;</span><span class="content">/ai/embedding</span><span class="delimiter">&quot;</span></span>)
    <span class="directive">public</span> <span class="predefined-type">Map</span> embed(<span class="annotation">@RequestParam</span>(value = <span class="string"><span class="delimiter">&quot;</span><span class="content">message</span><span class="delimiter">&quot;</span></span>, defaultValue = <span class="string"><span class="delimiter">&quot;</span><span class="content">Tell me a joke</span><span class="delimiter">&quot;</span></span>) <span class="predefined-type">String</span> message) {
        EmbeddingResponse embeddingResponse = <span class="local-variable">this</span>.embeddingClient.embedForResponse(<span class="predefined-type">List</span>.of(message));
        <span class="keyword">return</span> <span class="predefined-type">Map</span>.of(<span class="string"><span class="delimiter">&quot;</span><span class="content">embedding</span><span class="delimiter">&quot;</span></span>, embeddingResponse);
    }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_transcription_api">5.3.3. Transcription API</h4>
<div class="paragraph">
<p>El interfaz TranscriptionClient está diseñado para una integración sencilla con servicios de transcripción de voz a texto. Su función principal es convertir archivos de audio en texto, lo que permite a los desarrolladores integrar capacidades de transcripción en sus aplicaciones y sistemas.</p>
</div>
<div class="listingblock">
<div class="title">El pom.xml para la dependencia de Transcription API de Spring AI sería:</div>
<div class="content">
<pre>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.ai&lt;/groupId&gt;
    &lt;artifactId&gt;spring-ai-openai-spring-boot-starter&lt;/artifactId&gt;
&lt;/dependency&gt;</pre>
</div>
</div>
<div class="listingblock">
<div class="title">El build.gradle para la dependencia de Transcription API de Spring AI sería:</div>
<div class="content">
<pre>dependencies {
    implementation 'org.springframework.ai:spring-ai-openai-spring-boot-starter'
}</pre>
</div>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 9. Las propiedades de transcripción son:</caption>
<colgroup>
<col style="width: 28.5714%;">
<col style="width: 57.1428%;">
<col style="width: 14.2858%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Propiedad</th>
<th class="tableblock halign-left valign-top">Descripción</th>
<th class="tableblock halign-left valign-top">Predeterminado</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.audio.transcription.options.model</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ID del modelo a utilizar. Actualmente, solo está disponible whisper-1 (que está basado en nuestro modelo de código abierto Whisper V2).</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">whisper-1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.audio.transcription.options.response-format</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">El formato de salida de la transcripción, en una de estas opciones: json, text, srt, verbose_json, o vtt.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">json</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.audio.transcription.options.prompt</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Un texto opcional para guiar el estilo del modelo o continuar un segmento de audio anterior. El prompt debe coincidir con el idioma del audio.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.audio.transcription.options.language</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">El idioma del audio de entrada. Proporcionar el idioma de entrada en formato ISO-639-1 mejorará la precisión y la latencia.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.audio.transcription.options.temperature</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">La temperatura de muestreo, entre 0 y 1. Valores más altos como 0.8 harán que la salida sea más aleatoria, mientras que valores más bajos como 0.2 harán que sea más enfocada y determinista. Si se establece en 0, el modelo usará la probabilidad logarítmica para aumentar automáticamente la temperatura hasta que se alcancen ciertos umbrales.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.openai.audio.transcription.options.timestamp_granularities</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Las granularidades de las marcas de tiempo a poblar para esta transcripción. response_format debe estar configurado en verbose_json para usar granularidades de marcas de tiempo. Se admiten una o ambas de estas opciones: word o segment. Nota: No hay latencia adicional para marcas de tiempo de segmentos, pero generar marcas de tiempo de palabras genera latencia adicional.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">segment</p></td>
</tr>
</tbody>
</table>
<div class="listingblock">
<div class="title">Un ejemplo de código que usa el servicio de transcripción de OpenAI podría ser así:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="annotation">@RestController</span>
<span class="directive">public</span> <span class="type">class</span> <span class="class">TranscriptionController</span> {

    <span class="directive">private</span> <span class="directive">final</span> OpenAiAudioApi openAiAudioApi;

    <span class="directive">public</span> TranscriptionController(OpenAiAudioApi openAiAudioApi) {
        <span class="local-variable">this</span>.openAiAudioApi = openAiAudioApi;
    }

    <span class="annotation">@GetMapping</span>(<span class="string"><span class="delimiter">&quot;</span><span class="content">/ai/transcription</span><span class="delimiter">&quot;</span></span>)
    <span class="directive">public</span> <span class="predefined-type">Map</span>&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; transcription() {


        <span class="type">var</span> openAiAudioTranscriptionClient = <span class="keyword">new</span> OpenAiAudioTranscriptionClient(openAiAudioApi);

        <span class="type">var</span> transcriptionOptions = OpenAiAudioTranscriptionOptions.builder()
            .withResponseFormat(TranscriptResponseFormat.TEXT)
            .withTemperature(<span class="float">0f</span>)
            .build();

        <span class="type">var</span> audioFile = <span class="keyword">new</span> FileSystemResource(<span class="string"><span class="delimiter">&quot;</span><span class="content">/path/to/your/resource/speech/jfk.flac</span><span class="delimiter">&quot;</span></span>);

        AudioTranscriptionPrompt transcriptionRequest = <span class="keyword">new</span> AudioTranscriptionPrompt(audioFile, transcriptionOptions);
        AudioTranscriptionResponse response = openAiAudioTranscriptionClient.call(transcriptionRequest);
        <span class="keyword">return</span> <span class="predefined-type">Map</span>.of( <span class="string"><span class="delimiter">&quot;</span><span class="content">transcription</span><span class="delimiter">&quot;</span></span>, response.getResult().getOutput());
    }

}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_ollama_chat_completions_api">5.3.4. Ollama Chat completions API</h4>
<div class="paragraph">
<p>El interfaz OllamaChatClient está diseñado para una integración sencilla con el servicio de Chat Completions de Ollama. Su función principal es generar respuestas coherentes y relevantes en función de las entradas de texto proporcionadas.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 10. Las propiedades de chat son:</caption>
<colgroup>
<col style="width: 25%;">
<col style="width: 50%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Propiedad</th>
<th class="tableblock halign-left valign-top">Descripción</th>
<th class="tableblock halign-left valign-top">Valor por defecto</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.base-url</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">URL base donde se está ejecutando el servidor API de Ollama.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">localhost:11434</p></td>
</tr>
</tbody>
</table>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 11. Las opciones de configuración son:</caption>
<colgroup>
<col style="width: 25%;">
<col style="width: 50%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Propiedad  ```llama.chat.options.numa</th>
<th class="tableblock halign-left valign-top">Si se debe usar NUMA.</th>
<th class="tableblock halign-left valign-top">false</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.num-ctx</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Establece el tamaño de la ventana de contexto utilizada para generar el siguiente token.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2048</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.num-batch</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">???</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">512</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.num-gqa</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">El número de grupos GQA en la capa del transformador. Necesario para algunos modelos, por ejemplo, es 8 para llama2:70b.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.num-gpu</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">El número de capas a enviar a la(s) GPU(s). En macOS por defecto es 1 para habilitar el soporte de metal, 0 para deshabilitar. 1 aquí indica que NumGPU debe establecerse dinámicamente</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.main-gpu</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">define la GPU que se usa</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.low-vram</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">modo de funcionamiento en GPU con bajo uso de RAM</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.f16-kv</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">usar la representación de datos de coma flotante simplificada</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">true</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.logits-all</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">???</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.vocab-only</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">???</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.use-mmap</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">???</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">true</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.use-mlock</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">???</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.embedding-only</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">usar sólo representación de embeddings</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.rope-frequency-base</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">???</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">10000.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.rope-frequency-scale</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">???</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.num-thread</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Establece el número de hilos a utilizar durante la computación. Por defecto, Ollama detectará esto para un rendimiento óptimo. Se recomienda establecer este valor al número de núcleos físicos de la CPU de tu sistema (en lugar del número lógico de núcleos). 0 = dejar que el runtime decida</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.num-keep</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">???</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.seed</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Establece la semilla de números aleatorios a usar para la generación. Establecer esto a un número específico hará que el modelo genere el mismo texto para el mismo mensaje.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.num-predict</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Número máximo de tokens a predecir al generar texto. (-1 = generación infinita, -2 = llenar contexto)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.top-k</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Reduce la probabilidad de generar tonterías. Un valor más alto (por ejemplo, 100) dará respuestas más diversas, mientras que un valor más bajo (por ejemplo, 10) será más conservador.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">40</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.top-p</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Trabaja junto con top-k. Un valor más alto (por ejemplo, 0.95) llevará a texto más diverso, mientras que un valor más bajo (por ejemplo, 0.5) generará texto más enfocado y conservador.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.9</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.tfs-z</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">El muestreo sin cola se usa para reducir el impacto de los tokens menos probables en la salida. Un valor más alto (por ejemplo, 2.0) reducirá más el impacto, mientras que un valor de 1.0 desactiva esta configuración.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.typical-p</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">???</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.repeat-last-n</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Establece cuán atrás debe mirar el modelo para evitar repeticiones. (Por defecto: 64, 0 = deshabilitado, -1 = num_ctx)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">64</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.temperature</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">La temperatura del modelo. Aumentar la temperatura hará que el modelo responda de manera más creativa.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.8</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.repeat-penalty</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Establece cuán fuertemente penalizar las repeticiones. Un valor más alto (por ejemplo, 1.5) penalizará más fuertemente las repeticiones, mientras que un valor más bajo (por ejemplo, 0.9) será más indulgente.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.presence-penalty</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">???</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.frequency-penalty</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">???</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.mirostat</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Habilita el muestreo Mirostat para controlar la perplejidad. (por defecto: 0, 0 = deshabilitado, 1 = Mirostat, 2 = Mirostat 2.0)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.mirostat-tau</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Influye en la rapidez con la que el algoritmo responde a los comentarios del texto generado. Una tasa de aprendizaje más baja resultará en ajustes más lentos, mientras que una tasa de aprendizaje más alta hará que el algoritmo sea más receptivo.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">5.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.mirostat-eta</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Controla el equilibrio entre la coherencia y la diversidad de la salida. Un valor más bajo resultará en texto más enfocado y coherente.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.penalize-newline</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">???</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">true</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.chat.options.stop</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Establece las secuencias de parada a utilizar. Cuando se encuentre este patrón, el LLM dejará de generar texto y devolverá. Se pueden establecer múltiples patrones de parada especificando múltiples parámetros de parada separados en un archivo de modelo.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>Estas opciones de configuración permiten ajustar el comportamiento del modelo de Ollama Chat Completions para adaptarse a las necesidades específicas de la aplicación. Se suelen especificar en el archivo <code>application.properties</code> de Spring Boot.</p>
</div>
<div class="listingblock">
<div class="title">Es posible variar esta configuración en tiempo de ejecución, indicando las opciones en el objeto ChatOptions de la solicitud de Prompt:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">ChatResponse response = chatClient.call(
    <span class="keyword">new</span> Prompt(
        <span class="string"><span class="delimiter">&quot;</span><span class="content">Generate the names of 5 famous pirates.</span><span class="delimiter">&quot;</span></span>,
        OllamaOptions.create()
            .withModel(<span class="string"><span class="delimiter">&quot;</span><span class="content">llama2</span><span class="delimiter">&quot;</span></span>)
            .withTemperature(<span class="float">0.4</span>)
    ));</code></pre>
</div>
</div>
<div class="paragraph">
<p>Para poder usar el servicio de Chat Completions de Ollama, es necesario importar la dependencia de Ollama Chat Completions en el proyecto de Spring AI:</p>
</div>
<div class="listingblock">
<div class="title">Maven:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;dependency&gt;</span>
    <span class="tag">&lt;groupId&gt;</span>org.springframework.ai<span class="tag">&lt;/groupId&gt;</span>
    <span class="tag">&lt;artifactId&gt;</span>spring-ai-ollama<span class="tag">&lt;/artifactId&gt;</span>
<span class="tag">&lt;/dependency&gt;</span></code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Gradle:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="groovy">dependencies {
    implementation <span class="string"><span class="delimiter">'</span><span class="content">org.springframework.ai:spring-ai-ollama</span><span class="delimiter">'</span></span>
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>En el ejemplo anterior, se solicita al modelo de Ollama que genere los nombres de 5 piratas famosos con un modelo llama2 y una temperatura de 0.4. Estas opciones se pueden ajustar según las necesidades de la aplicación y el contexto de la conversación.</p>
</div>
<div class="listingblock">
<div class="title">Un ejemplo de application.properties para configurar el servicio de Chat Completions de Ollama podría ser así:</div>
<div class="content">
<pre class="CodeRay highlight"><code>spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.chat.options.model=ollama3
spring.ai.ollama.chat.options.temperature=0.7</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Un ejemplo de controlador de Spring Boot para el servicio de Chat Completions de Ollama podría ser así:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="annotation">@RestController</span>
<span class="directive">public</span> <span class="type">class</span> <span class="class">ChatController</span> {

    <span class="directive">private</span> <span class="directive">final</span> OllamaChatClient chatClient;

    <span class="annotation">@Autowired</span>
    <span class="directive">public</span> ChatController(OllamaChatClient chatClient) {
        <span class="local-variable">this</span>.chatClient = chatClient;
    }

    <span class="annotation">@GetMapping</span>(<span class="string"><span class="delimiter">&quot;</span><span class="content">/ai/generate</span><span class="delimiter">&quot;</span></span>)
    <span class="directive">public</span> <span class="predefined-type">Map</span> generate(<span class="annotation">@RequestParam</span>(value = <span class="string"><span class="delimiter">&quot;</span><span class="content">message</span><span class="delimiter">&quot;</span></span>, defaultValue = <span class="string"><span class="delimiter">&quot;</span><span class="content">Tell me a joke</span><span class="delimiter">&quot;</span></span>) <span class="predefined-type">String</span> message) {
        <span class="keyword">return</span> <span class="predefined-type">Map</span>.of(<span class="string"><span class="delimiter">&quot;</span><span class="content">generation</span><span class="delimiter">&quot;</span></span>, chatClient.call(message));
    }

    <span class="annotation">@GetMapping</span>(<span class="string"><span class="delimiter">&quot;</span><span class="content">/ai/generateStream</span><span class="delimiter">&quot;</span></span>)
        <span class="directive">public</span> Flux&lt;ChatResponse&gt; generateStream(<span class="annotation">@RequestParam</span>(value = <span class="string"><span class="delimiter">&quot;</span><span class="content">message</span><span class="delimiter">&quot;</span></span>, defaultValue = <span class="string"><span class="delimiter">&quot;</span><span class="content">Tell me a joke</span><span class="delimiter">&quot;</span></span>) <span class="predefined-type">String</span> message) {
        Prompt prompt = <span class="keyword">new</span> Prompt(<span class="keyword">new</span> UserMessage(message));
        <span class="keyword">return</span> chatClient.stream(prompt);
    }

}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_ollama_embeddings_api">5.3.5. Ollama Embeddings API</h4>
<div class="paragraph">
<p>Ollama embeddings proporciona la representaciones vectoriales que capturan la semántica y el contexto del texto, lo que permite a los desarrolladores realizar tareas como análisis de sentimientos, clasificación de texto y búsqueda semántica.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 12. Las propiedades de Ollama Embeddings son:</caption>
<colgroup>
<col style="width: 25%;">
<col style="width: 50%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Propiedad</th>
<th class="tableblock halign-left valign-top">Descripción</th>
<th class="tableblock halign-left valign-top">Valor por defecto</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.base-url</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">URL base donde se está ejecutando el servidor API de Ollama.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">localhost:11434</p>
<p class="tableblock">El prefijo <code>spring.ai.ollama.embedding.options</code> es el prefijo de propiedad que configura la implementación de EmbeddingClient para Ollama.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Propiedad</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Descripción</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Valor por defecto</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.enabled</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Habilita el cliente de embedding de Ollama.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">true</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.model (DEPRECATED)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">El nombre del modelo a usar. Obsoleto, use <code>spring.ai.ollama.embedding.options.model</code> en su lugar.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">mistral</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.model</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">El nombre de los modelos compatibles a usar.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">mistral</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.numa</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Si se debe usar NUMA.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.num-ctx</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Establece el tamaño de la ventana de contexto utilizada para generar el siguiente token.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2048</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.num-batch</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Establece el número de lotes (batches) a procesar simultáneamente.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.num-gqa</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">El número de grupos GQA en la capa del transformador. Necesario para algunos modelos, por ejemplo, es 8 para llama2:70b.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.num-gpu</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">El número de capas a enviar a la(s) GPU(s). En macOS por defecto es 1 para habilitar el soporte de metal, 0 para deshabilitar.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.main-gpu</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">El índice de la GPU principal a usar.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.low-vram</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Si se debe usar un modo de baja VRAM para ahorrar memoria.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.f16-kv</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Si se debe utilizar una representación de 16 bits (half precision) para las claves y valores (key-value).</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.logits-all</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Si se deben devolver todos los logits en lugar de solo el más alto.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.vocab-only</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Si se debe cargar solo el vocabulario, sin los pesos del modelo.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.use-mmap</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Si se debe utilizar mmap para asignar archivos en memoria, mejorando la gestión de memoria.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.use-mlock</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Si se debe usar mlock para bloquear las páginas de memoria en RAM, evitando que se intercambien.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.embedding-only</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Si se debe ejecutar en modo solo de embedding, sin generación de texto.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.rope-frequency-base</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">La base de frecuencia para la codificación posicional ROPE (Rotary Position Embedding).</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.rope-frequency-scale</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">La escala de frecuencia para la codificación posicional ROPE.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.num-thread</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Establece el número de hilos a utilizar durante la computación. Por defecto, Ollama detectará esto para un rendimiento óptimo. Se recomienda establecer este valor al número de núcleos físicos de la CPU de tu sistema (en lugar del número lógico de núcleos).</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.num-keep</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">El número de tokens a mantener en la memoria al hacer recortes de contexto.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.seed</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Establece la semilla de números aleatorios a usar para la generación. Establecer esto a un número específico hará que el modelo genere el mismo texto para el mismo mensaje.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.num-predict</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Número máximo de tokens a predecir al generar texto. (Por defecto: 128, -1 = generación infinita, -2 = llenar contexto)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">128</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.top-k</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Reduce la probabilidad de generar tonterías. Un valor más alto (por ejemplo, 100) dará respuestas más diversas, mientras que un valor más bajo (por ejemplo, 10) será más conservador.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">40</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.top-p</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Trabaja junto con top-k. Un valor más alto (por ejemplo, 0.95) llevará a texto más diverso, mientras que un valor más bajo (por ejemplo, 0.5) generará texto más enfocado y conservador.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.9</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.tfs-z</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">El muestreo sin cola se usa para reducir el impacto de los tokens menos probables en la salida. Un valor más alto (por ejemplo, 2.0) reducirá más el impacto, mientras que un valor de 1.0 desactiva esta configuración.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.typical-p</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Utiliza la probabilidad típica para ajustar la generación de texto, manteniendo la generación dentro de límites razonables.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.repeat-last-n</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Establece cuán atrás debe mirar el modelo para evitar repeticiones. (Por defecto: 64, 0 = deshabilitado, -1 = num_ctx)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">64</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.temperature</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">La temperatura del modelo. Aumentar la temperatura hará que el modelo responda de manera más creativa.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.8</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.repeat-penalty</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Establece cuán fuertemente penalizar las repeticiones. Un valor más alto (por ejemplo, 1.5) penalizará más fuertemente las repeticiones, mientras que un valor más bajo (por ejemplo, 0.9) será más indulgente.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.presence-penalty</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Penaliza la aparición de nuevas palabras que no se han visto antes en el contexto.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.frequency-penalty</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Penaliza la repetición de palabras basándose en su frecuencia.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.mirostat</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Habilita el muestreo Mirostat para controlar la perplejidad. (por defecto: 0, 0 = deshabilitado, 1 = Mirostat, 2 = Mirostat 2.0)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.mirostat-tau</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Influye en la rapidez con la que el algoritmo responde a los comentarios del texto generado. Una tasa de aprendizaje más baja resultará en ajustes más lentos, mientras que una tasa de aprendizaje más alta hará que el algoritmo sea más receptivo.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">5.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.mirostat-eta</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Controla el equilibrio entre la coherencia y la diversidad de la salida. Un valor más bajo resultará en texto más enfocado y coherente.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.penalize-newline</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Penaliza la generación de nuevas líneas en el texto generado.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spring.ai.ollama.embedding.options.stop</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Establece las secuencias de parada a utilizar. Cuando se encuentre este patrón, el LLM dejará de generar texto y devolverá. Se pueden establecer múltiples patrones de parada especificando múltiples parámetros de parada separados en un archivo de modelo.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
</tbody>
</table>
<div class="listingblock">
<div class="title">Un ejemplo de aplicación.properties para configurar el servicio de Embeddings de Ollama podría ser así:</div>
<div class="content">
<pre class="CodeRay highlight"><code>spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.embedding.options.model=llama3</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Un ejemplo de controlador de Spring Boot para el servicio de Embeddings de Ollama podría ser así:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="annotation">@RestController</span>
<span class="directive">public</span> <span class="type">class</span> <span class="class">EmbeddingController</span> {

    <span class="directive">private</span> <span class="directive">final</span> EmbeddingClient embeddingClient;

    <span class="annotation">@Autowired</span>
    <span class="directive">public</span> EmbeddingController(EmbeddingClient embeddingClient) {
        <span class="local-variable">this</span>.embeddingClient = embeddingClient;
    }

    <span class="annotation">@GetMapping</span>(<span class="string"><span class="delimiter">&quot;</span><span class="content">/ai/embedding</span><span class="delimiter">&quot;</span></span>)
    <span class="directive">public</span> <span class="predefined-type">Map</span> embed(<span class="annotation">@RequestParam</span>(value = <span class="string"><span class="delimiter">&quot;</span><span class="content">message</span><span class="delimiter">&quot;</span></span>, defaultValue = <span class="string"><span class="delimiter">&quot;</span><span class="content">Tell me a joke</span><span class="delimiter">&quot;</span></span>) <span class="predefined-type">String</span> message) {
        EmbeddingResponse embeddingResponse = <span class="local-variable">this</span>.embeddingClient.embedForResponse(<span class="predefined-type">List</span>.of(message));
        <span class="keyword">return</span> <span class="predefined-type">Map</span>.of(<span class="string"><span class="delimiter">&quot;</span><span class="content">embedding</span><span class="delimiter">&quot;</span></span>, embeddingResponse);
    }
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_bases_de_datos_vectoriales_en_spring_ai">5.3.6. Bases de datos vectoriales en Spring AI</h4>
<div class="paragraph">
<p>Las bases de datos vectoriales son una forma eficiente de almacenar y recuperar vectores multi dimensionales, como los embeddings generados por modelos de lenguaje. Estas bases de datos permiten realizar consultas de similitud y búsqueda de vecinos cercanos en un espacio de vectores, lo que resulta útil en aplicaciones como la recuperación de información, la agrupación y la detección de duplicados.</p>
</div>
<div class="paragraph">
<p>El primer paso en su uso es cargar los datos en una base de datos vectorial. Luego, cuando se envía una consulta de usuario al modelo de IA, primero se recuperan un conjunto de documentos similares. Estos documentos luego sirven como contexto para la pregunta del usuario y se envían al modelo de IA, junto con la consulta del usuario. Esta técnica se conoce como Generación Aumentada por Recuperación (RAG).</p>
</div>
<div class="listingblock">
<div class="title">La definición de la interfaz <code>VectorStore</code> es:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">interface</span> <span class="class">VectorStore</span> {

    <span class="type">void</span> add(<span class="predefined-type">List</span>&lt;<span class="predefined-type">Document</span>&gt; documents);

    Optional&lt;<span class="predefined-type">Boolean</span>&gt; delete(<span class="predefined-type">List</span>&lt;<span class="predefined-type">String</span>&gt; idList);

    <span class="predefined-type">List</span>&lt;<span class="predefined-type">Document</span>&gt; similaritySearch(<span class="predefined-type">String</span> query);

    <span class="predefined-type">List</span>&lt;<span class="predefined-type">Document</span>&gt; similaritySearch(SearchRequest request);
}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">La definición de la clase <code>SearchRequest</code> es:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">class</span> <span class="class">SearchRequest</span> {

        <span class="directive">public</span> <span class="directive">final</span> <span class="predefined-type">String</span> query;
        <span class="directive">private</span> <span class="type">int</span> topK = <span class="integer">4</span>;
        <span class="directive">private</span> <span class="type">double</span> similarityThreshold = SIMILARITY_THRESHOLD_ALL;
        <span class="directive">private</span> <span class="predefined-type">Filter</span>.Expression filterExpression;

        <span class="directive">public</span> <span class="directive">static</span> SearchRequest query(<span class="predefined-type">String</span> query) { <span class="keyword">return</span> <span class="keyword">new</span> SearchRequest(query); }

        <span class="directive">private</span> SearchRequest(<span class="predefined-type">String</span> query) { <span class="local-variable">this</span>.query = query; }

        <span class="directive">public</span> SearchRequest withTopK(<span class="type">int</span> topK) {...}
        <span class="directive">public</span> SearchRequest withSimilarityThreshold(<span class="type">double</span> threshold) {...}
        <span class="directive">public</span> SearchRequest withSimilarityThresholdAll() {...}
        <span class="directive">public</span> SearchRequest withFilterExpression(<span class="predefined-type">Filter</span>.Expression expression) {...}
        <span class="directive">public</span> SearchRequest withFilterExpression(<span class="predefined-type">String</span> textExpression) {...}

        <span class="directive">public</span> <span class="predefined-type">String</span> getQuery() {...}
        <span class="directive">public</span> <span class="type">int</span> getTopK() {...}
        <span class="directive">public</span> <span class="type">double</span> getSimilarityThreshold() {...}
        <span class="directive">public</span> <span class="predefined-type">Filter</span>.Expression getFilterExpression() {...}
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Para insertar datos en la base de datos vectorial, se encapsulan en un objeto Document. La clase Document aglutina el contenido de una fuente de datos, como un documento PDF o de Word, e incluye texto representado como una cadena. También contiene metadatos en forma de pares clave-valor, incluyendo detalles como el nombre del archivo.</p>
</div>
<div class="paragraph">
<p>El rol de las bases de datos vectoriales es almacenar y facilitar búsquedas de similitud para estos embeddings. No genera los embeddings en sí. Para crear embeddings vectoriales, se debe utilizar el EmbeddingClient.</p>
</div>
<div class="paragraph">
<p>Los métodos similaritySearch en la interfaz permiten recuperar documentos similares a una cadena de consulta dada. Estos métodos se pueden ajustar utilizando los siguientes parámetros:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>k:</strong> Un número entero que especifica el número máximo de documentos similares a devolver. A menudo se denomina búsqueda 'top K' o 'K vecinos más cercanos' (KNN).</p>
</li>
<li>
<p><strong>threshold:</strong> Un valor decimal (doble) que varía de 0 a 1, donde los valores más cercanos a 1 indican una mayor similitud. De forma predeterminada, si estableces un umbral de 0.75, por ejemplo, solo se devuelven los documentos con una similitud superior a este valor.</p>
</li>
<li>
<p><strong>Filter.Expression:</strong> Una clase utilizada para pasar una expresión DSL (Domain-Specific Language) fluida que funciona de manera similar a una cláusula 'where' en SQL, pero se aplica exclusivamente a los pares clave-valor de metadatos de un Documento.</p>
</li>
<li>
<p><strong>filterExpression:</strong> Un DSL externo basado en ANTLR4 que acepta expresiones de filtro como cadenas. Por ejemplo, con claves de metadatos como país, año y isActive, podrías usar una expresión como: país == 'UK' &amp;&amp; año &gt;= 2020 &amp;&amp; isActive == true.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>El uso general de la carga de datos en un almacén de vectores es algo que harías en un trabajo tipo lote, primero cargando datos en la clase Document de Spring AI y luego llamando al método save.</p>
</div>
<div class="paragraph">
<p>Si tienes un archivo JSON con datos que deseas cargar en la base de datos vectorial, puedes usar la clase JsonReader de Spring AI para cargar campos específicos en el JSON, dividirlos en piezas pequeñas y luego pasar esas piezas pequeñas a la implementación de VectorStore.</p>
</div>
<div class="listingblock">
<div class="title">La implementación de VectorStore calcula los embeddings y almacena el JSON y el embedding en la base de datos vectorial:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="annotation">@Autowired</span>
VectorStore vectorStore;

<span class="comment">// Load data into the vector store</span>
<span class="type">void</span> load(<span class="predefined-type">String</span> sourceFile) {
        JsonReader jsonReader = <span class="keyword">new</span> JsonReader(<span class="keyword">new</span> FileSystemResource(sourceFile),
                <span class="string"><span class="delimiter">&quot;</span><span class="content">price</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">shortDescription</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">description</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">tags</span><span class="delimiter">&quot;</span></span>);
        <span class="predefined-type">List</span>&lt;<span class="predefined-type">Document</span>&gt; documents = jsonReader.get();
        <span class="local-variable">this</span>.vectorStore.add(documents);
}

<span class="comment">// Query the vector store</span>
<span class="predefined-type">String</span> query(<span class="predefined-type">String</span> query) {
        <span class="predefined-type">List</span>&lt;<span class="predefined-type">Document</span>&gt; documents = <span class="local-variable">this</span>.vectorStore.similaritySearch(query);
        <span class="keyword">return</span> documents.get(<span class="integer">0</span>).getContent();
}

<span class="comment">// remove data from the vector store</span>
<span class="type">void</span> remove(<span class="predefined-type">List</span>&lt;<span class="predefined-type">String</span>&gt; idList) {
        <span class="local-variable">this</span>.vectorStore.delete(idList);
}</code></pre>
</div>
</div>
<div class="ulist">
<div class="title">Los mmétodos para trabajar con la base de datos vectorial son:</div>
<ul>
<li>
<p><strong>add:</strong> Agrega una lista de documentos a la base de datos vectorial.</p>
</li>
<li>
<p><strong>delete:</strong> Elimina una lista de documentos de la base de datos vectorial.</p>
</li>
<li>
<p><strong>similaritySearch:</strong> Realiza una búsqueda de similitud en la base de datos vectorial y devuelve una lista de documentos similares. Usa una cadena de consulta.</p>
</li>
<li>
<p><strong>similaritySearch:</strong> Realiza una búsqueda de similitud en la base de datos vectorial y devuelve una lista de documentos similares, utilizando un objeto <strong>SearchRequest</strong>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Es posible crear una instancia de Filter.Expression con un FilterExpressionBuilder.</p>
</div>
<div class="listingblock">
<div class="title">Un ejemplo simple es el siguiente:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">Filter</span>.Expression filterExpression = FilterExpressionBuilder.create()
    .withKey(<span class="string"><span class="delimiter">&quot;</span><span class="content">country</span><span class="delimiter">&quot;</span></span>).isEqualTo(<span class="string"><span class="delimiter">&quot;</span><span class="content">UK</span><span class="delimiter">&quot;</span></span>)
    .and()
    .withKey(<span class="string"><span class="delimiter">&quot;</span><span class="content">year</span><span class="delimiter">&quot;</span></span>).isGreaterThanOrEqualTo(<span class="integer">2020</span>)
    .and()
    .withKey(<span class="string"><span class="delimiter">&quot;</span><span class="content">isActive</span><span class="delimiter">&quot;</span></span>).isEqualTo(<span class="predefined-constant">true</span>)
    .build();</code></pre>
</div>
</div>
<div class="ulist">
<div class="title">Los operadores disponibles en Filter.Expression son:</div>
<ul>
<li>
<p><strong>isEqualTo:</strong> Igual a</p>
</li>
<li>
<p><strong>isNotEqualTo:</strong> No igual a</p>
</li>
<li>
<p><strong>isGreaterThan:</strong> Mayor que</p>
</li>
<li>
<p><strong>isGreaterThanOrEqualTo:</strong> Mayor o igual que</p>
</li>
<li>
<p><strong>isLessThan:</strong> Menor que</p>
</li>
<li>
<p><strong>isLessThanOrEqualTo:</strong> Menor o igual que</p>
</li>
<li>
<p><strong>contains:</strong> Contiene</p>
</li>
<li>
<p><strong>startsWith:</strong> Comienza con</p>
</li>
<li>
<p><strong>endsWith:</strong> Termina con</p>
</li>
<li>
<p><strong>matches:</strong> Coincide con una expresión regular</p>
</li>
<li>
<p><strong>isIn:</strong> Está en una lista de valores</p>
</li>
<li>
<p><strong>isNotIn:</strong> No está en una lista de valores</p>
</li>
<li>
<p><strong>and:</strong> Operador lógico AND</p>
</li>
<li>
<p><strong>or:</strong> Operador lógico OR</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Un enlace interesante para comprender mejor los vectores y las bases de datos vectoriales es el siguiente: <a href="https://docs.spring.io/spring-ai/reference/api/vectordbs/understand-vectordbs.html" class="bare">https://docs.spring.io/spring-ai/reference/api/vectordbs/understand-vectordbs.html</a></p>
</div>
<div class="sect4">
<h5 id="_qdrant_en_spring_ai">Qdrant en Spring AI</h5>
<div class="paragraph">
<p>Qdrant es una base de datos vectorial de código abierto que permite almacenar y recuperar vectores multi dimensionales, como los embeddings generados por modelos de lenguaje. Qdrant es una base de datos de búsqueda de vecinos más cercanos (KNN) que facilita la búsqueda de documentos similares en un espacio de vectores.</p>
</div>
<div class="listingblock">
<div class="title">La forma más rápida de crear una instancia de Qdrant es con Docker:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">docker run -d --name qdrant -p 6334:6334 -p 6333:6333 -v /path/to/data:/data qdrant/qdrant</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Para usar Qdrant en Spring AI, primero debes agregar la dependencia de Qdrant en tu proyecto:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;dependency&gt;</span>
        <span class="tag">&lt;groupId&gt;</span>org.springframework.ai<span class="tag">&lt;/groupId&gt;</span>
        <span class="tag">&lt;artifactId&gt;</span>spring-ai-qdrant-store-spring-boot-starter<span class="tag">&lt;/artifactId&gt;</span>
<span class="tag">&lt;/dependency&gt;</span></code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">En Gradle, la dependencia de Qdrant se vería así:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="groovy">dependencies {
    implementation <span class="string"><span class="delimiter">'</span><span class="content">org.springframework.ai:spring-ai-qdrant-store-spring-boot-starter</span><span class="delimiter">'</span></span>
}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">En el archivo <code>application.properties</code>, debes configurar las propiedades de conexión a Qdrant:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="properties">spring.ai.vectorstore.qdrant.host=&lt;la dirección IP de tu instancia de Qdrant&gt;
spring.ai.vectorstore.qdrant.port=&lt;el puerto de gRPC de tu instancia de Qdrant (default: 6334)&gt;
spring.ai.vectorstore.qdrant.api-key=&lt;la clave API de tu instancia de Qdrant&gt;
spring.ai.vectorstore.qdrant.collection-name=&lt;el nombre de la colección de vectores en Qdrant&gt;
spring.ai.vectorstore.qdrant.use-tls=&lt;true o false&gt;

# API key if needed, e.g. OpenAI
spring.ai.openai.api.key=&lt;api-key&gt;</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Un ejemplo de controlador de Spring Boot para el servicio de Qdrant podría ser así:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="annotation">@RestController</span>
<span class="directive">public</span> <span class="type">class</span> <span class="class">QdrantController</span> {

    <span class="directive">private</span> <span class="directive">final</span> VectorStore vectorStore;

    <span class="annotation">@Autowired</span>
    <span class="directive">public</span> QdrantController(VectorStore vectorStore) {
        <span class="local-variable">this</span>.vectorStore = vectorStore;
    }

    <span class="annotation">@GetMapping</span>(<span class="string"><span class="delimiter">&quot;</span><span class="content">/ai/qdrant/load</span><span class="delimiter">&quot;</span></span>)
    <span class="directive">public</span> <span class="type">void</span> load(<span class="annotation">@RequestParam</span>(value = <span class="string"><span class="delimiter">&quot;</span><span class="content">sourceFile</span><span class="delimiter">&quot;</span></span>, defaultValue = <span class="string"><span class="delimiter">&quot;</span><span class="content">data.json</span><span class="delimiter">&quot;</span></span>) <span class="predefined-type">String</span> sourceFile) {
        JsonReader jsonReader = <span class="keyword">new</span> JsonReader(<span class="keyword">new</span> FileSystemResource(sourceFile),
                <span class="string"><span class="delimiter">&quot;</span><span class="content">price</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">shortDescription</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">description</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">tags</span><span class="delimiter">&quot;</span></span>);
        <span class="predefined-type">List</span>&lt;<span class="predefined-type">Document</span>&gt; documents = jsonReader.get();
        <span class="local-variable">this</span>.vectorStore.add(documents);
    }

    <span class="annotation">@GetMapping</span>(<span class="string"><span class="delimiter">&quot;</span><span class="content">/ai/qdrant/query</span><span class="delimiter">&quot;</span></span>)
    <span class="directive">public</span> <span class="predefined-type">String</span> query(<span class="annotation">@RequestParam</span>(value = <span class="string"><span class="delimiter">&quot;</span><span class="content">query</span><span class="delimiter">&quot;</span></span>, defaultValue = <span class="string"><span class="delimiter">&quot;</span><span class="content">Tell me a joke</span><span class="delimiter">&quot;</span></span>) <span class="predefined-type">String</span> query) {
        vectorStore.similaritySearch(SearchRequest.defaults()
        .withQuery(<span class="string"><span class="delimiter">&quot;</span><span class="content">The World</span><span class="delimiter">&quot;</span></span>)
        .withTopK(TOP_K)
        .withSimilarityThreshold(SIMILARITY_THRESHOLD)
        .withFilterExpression(<span class="string"><span class="delimiter">&quot;</span><span class="content">author in ['john', 'jill'] &amp;&amp; article_type == 'blog'</span><span class="delimiter">&quot;</span></span>));
    }

    <span class="annotation">@GetMapping</span>(<span class="string"><span class="delimiter">&quot;</span><span class="content">/ai/qdrant/remove</span><span class="delimiter">&quot;</span></span>)
    <span class="directive">public</span> <span class="type">void</span> remove(<span class="annotation">@RequestParam</span>(value = <span class="string"><span class="delimiter">&quot;</span><span class="content">idList</span><span class="delimiter">&quot;</span></span>) <span class="predefined-type">List</span>&lt;<span class="predefined-type">String</span>&gt; idList) {
        <span class="local-variable">this</span>.vectorStore.delete(idList);
    }
}</code></pre>
</div>
</div>
<div class="ulist">
<div class="title">Para hacer peticiones a una base de datos vectorial Qdrant, hay 2 métodos:</div>
<ul>
<li>
<p>El lenjuage de expresión de texto: "author in ['john', 'jill'] &amp;&amp; article_type == 'blog'"</p>
</li>
<li>
<p>El DSL Filter.Expression: de una forma más programática</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Ejemplo de Lenjuage de expresión de texto:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">vectorStore.similaritySearch(SearchRequest.defaults()
        .withQuery(<span class="string"><span class="delimiter">&quot;</span><span class="content">The World</span><span class="delimiter">&quot;</span></span>)
        .withTopK(TOP_K)
        .withSimilarityThreshold(SIMILARITY_THRESHOLD)
        .withFilterExpression(<span class="string"><span class="delimiter">&quot;</span><span class="content">author in ['john', 'jill'] &amp;&amp; article_type == 'blog'</span><span class="delimiter">&quot;</span></span>));</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Ejemplo de DSL Filter.Expression:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">FilterExpressionBuilder b = <span class="keyword">new</span> FilterExpressionBuilder();

vectorStore.similaritySearch(SearchRequest.defaults()
    .withQuery(<span class="string"><span class="delimiter">&quot;</span><span class="content">The World</span><span class="delimiter">&quot;</span></span>)
    .withTopK(TOP_K)
    .withSimilarityThreshold(SIMILARITY_THRESHOLD)
    .withFilterExpression(b.and(
        b.in(<span class="string"><span class="delimiter">&quot;</span><span class="content">john</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">jill</span><span class="delimiter">&quot;</span></span>),
        b.eq(<span class="string"><span class="delimiter">&quot;</span><span class="content">article_type</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">blog</span><span class="delimiter">&quot;</span></span>)).build()));</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Ejemplo para borrar datos de la base de datos vectorial:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">vectorStore.delete(idList);</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2025-06-05 17:46:11 +0200
</div>
</div>
</body>
</html>