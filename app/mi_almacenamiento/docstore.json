{"docstore/metadata": {"efaff6ab-6f5b-4126-bcc7-1d17ce5e25e4": {"doc_hash": "5e327376077faf09c956464df4f5f70c8266bcfad3fad5763b907542011a5a33"}, "b34e700b-3828-4e7d-9b87-2842b478530e": {"doc_hash": "41af192bbaad64f68b4851fa77a3f262756d73ac99592446700d57b388469a47", "ref_doc_id": "efaff6ab-6f5b-4126-bcc7-1d17ce5e25e4"}, "8378b0a8-5338-44bd-b966-fd563b71661f": {"doc_hash": "022a95b9e4adc2aa1ef27c4993d84a280c8dbf3f81292bbb6a473e77617f0e56", "ref_doc_id": "efaff6ab-6f5b-4126-bcc7-1d17ce5e25e4"}, "c3383793-fb39-45d9-bd18-918b23b92702": {"doc_hash": "f095464016b56fa89ca1e42752545df088e5a2a212f92f9d3252b12c3cafa794", "ref_doc_id": "efaff6ab-6f5b-4126-bcc7-1d17ce5e25e4"}, "b5e4a2b1-142b-406b-b718-4363443b181d": {"doc_hash": "bcba73875fbc4540a924263836a182b9958048c8c2a4106bc253710b035f7406", "ref_doc_id": "efaff6ab-6f5b-4126-bcc7-1d17ce5e25e4"}, "c4331a8a-42fe-4ef4-9883-02a7bc2e939f": {"doc_hash": "c16db03cdb9733b7efaf31026d21d2a396ebe2c78b3765a8fc89d1fef1bb2f73", "ref_doc_id": "efaff6ab-6f5b-4126-bcc7-1d17ce5e25e4"}, "ff402985-4272-4131-99bc-e16392610807": {"doc_hash": "a29c61adf9891947858fbe076823aaed68d28da8149790ef4373a8d3c6d29170", "ref_doc_id": "efaff6ab-6f5b-4126-bcc7-1d17ce5e25e4"}, "08768263-fa37-4ac9-8f5f-91eb7df23e49": {"doc_hash": "0ae69e7bda6f82c1bb8370489ad43edac822f9673b8961028f2f141496ebedad", "ref_doc_id": "efaff6ab-6f5b-4126-bcc7-1d17ce5e25e4"}}, "docstore/data": {"b34e700b-3828-4e7d-9b87-2842b478530e": {"__data__": {"id_": "b34e700b-3828-4e7d-9b87-2842b478530e", "embedding": null, "metadata": {"file_path": "/home/rojaldo/cursos/llm/llamaindex/docs/ia.md", "file_name": "ia.md", "file_type": "text/markdown", "file_size": 20595, "creation_date": "2025-06-04", "last_modified_date": "2025-06-04"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "efaff6ab-6f5b-4126-bcc7-1d17ce5e25e4", "node_type": "4", "metadata": {"file_path": "/home/rojaldo/cursos/llm/llamaindex/docs/ia.md", "file_name": "ia.md", "file_type": "text/markdown", "file_size": 20595, "creation_date": "2025-06-04", "last_modified_date": "2025-06-04"}, "hash": "5e327376077faf09c956464df4f5f70c8266bcfad3fad5763b907542011a5a33", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8378b0a8-5338-44bd-b966-fd563b71661f", "node_type": "1", "metadata": {}, "hash": "7e296735e8e1fd21f92ead87b53e1d05627a8bff7972dea90099c49c5e796d73", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# Inteligencia artificial\n\n## Introducci\u00f3n\n\nLa inteligencia artificial (IA) es la inteligencia exhibida por m\u00e1quinas. En ciencias de la computaci\u00f3n, una m\u00e1quina \"inteligente\" ideal es un agente racional flexible que percibe su entorno y lleva a cabo acciones que maximicen sus posibilidades de \u00e9xito en alg\u00fan objetivo o tarea. Colloquialmente, el t\u00e9rmino inteligencia artificial se aplica cuando una m\u00e1quina imita las funciones \"cognitivas\" que los humanos asocian con otras mentes humanas, como \"aprender\" y \"resolver problemas\".\n\n## Historia\n\nEl t\u00e9rmino \"inteligencia artificial\" fue acu\u00f1ado por John McCarthy en 1956, en la conferencia de Dartmouth College, Massachusetts. La inteligencia artificial es un campo de estudio multidisciplinario que busca, mediante el uso de modelos computacionales, el desarrollo de sistemas que puedan realizar tareas que, de momento, requieren inteligencia humana para ser realizadas. La inteligencia artificial es una rama de la inform\u00e1tica que se ocupa de la creaci\u00f3n de programas y mecanismos que pueden mostrar comportamientos que podr\u00edan considerarse inteligentes.\n\n## Hitos en la Historia de la IA\n\n- **1956:** John McCarthy acu\u00f1a el t\u00e9rmino \"inteligencia artificial\" en la conferencia de Dartmouth College.\n- **1958:** Herbert Simon y Allen Newell desarrollan el programa de l\u00f3gica simb\u00f3lica \"Logic Theorist\".\n- **1965:** Joseph Weizenbaum crea el programa de procesamiento de lenguaje natural \"ELIZA\".\n- **1979:** Douglas Lenat desarrolla el programa de razonamiento \"AM\".\n- **1997:** Deep Blue, de IBM, derrota al campe\u00f3n mundial de ajedrez Garry Kasparov.\n- **2011:** IBM Watson gana el concurso de televisi\u00f3n \"Jeopardy!\".\n- **2016:** AlphaGo, de DeepMind, derrota al campe\u00f3n mundial de Go, Lee Sedol.\n- **2020:** AlphaFold, de DeepMind, predice la estructura de prote\u00ednas con una precisi\u00f3n sin precedentes.\n- **2021:** GPT-3, de OpenAI, es lanzado y muestra un rendimiento sobresaliente en tareas de procesamiento del lenguaje natural.\n- **2023:** GNoMe, de DeepMind, permite predecir materiales con propiedades espec\u00edficas a partir de su estructura at\u00f3mica y estructuras cristalinas.\n\n## Primeras T\u00e9cnicas Utilizadas en IA\n\n### L\u00f3gica y Reglas Heur\u00edsticas\n\nSe utilizaron reglas de l\u00f3gica y heur\u00edsticas para representar el conocimiento y las estrategias de resoluci\u00f3n de problemas. Estas reglas se aplicaron en sistemas expertos tempranos para modelar el razonamiento humano en dominios espec\u00edficos.\n\n### \u00c1rboles de B\u00fasqueda y Algoritmos de B\u00fasqueda\n\nSe desarrollaron algoritmos de b\u00fasqueda como el algoritmo de b\u00fasqueda en anchura y el algoritmo de b\u00fasqueda en profundidad para encontrar soluciones a problemas mediante la exploraci\u00f3n de un espacio de estados.\n\n### Redes Neuronales Artificiales (ANN)\n\nAunque las ideas detr\u00e1s de las redes neuronales se originaron en la d\u00e9cada de 1940, se utilizaron m\u00e1s ampliamente en las d\u00e9cadas de 1950 y 1960 para modelar el comportamiento de las neuronas y para abordar problemas de aprendizaje autom\u00e1tico y reconocimiento de patrones.\n\n### Sistemas Expertos\n\nLos sistemas expertos, que representaban el conocimiento en forma de reglas if-then y utilizaban motores de inferencia para razonar sobre ese conocimiento, fueron una de las primeras aplicaciones pr\u00e1cticas de la IA en campos como la medicina, la ingenier\u00eda y el diagn\u00f3stico.\n\n### Programaci\u00f3n Simb\u00f3lica\n\nSe desarrollaron lenguajes de programaci\u00f3n simb\u00f3lica como Lisp para manipular s\u00edmbolos y representar el conocimiento de una manera m\u00e1s abstracta, lo que facilitaba la implementaci\u00f3n de sistemas inteligentes.\n\n### Teor\u00eda de Juegos y Planificaci\u00f3n\n\nSe aplicaron principios de teor\u00eda de juegos y planificaci\u00f3n para desarrollar agentes inteligentes capaces de tomar decisiones en entornos complejos y competitivos.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3761, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8378b0a8-5338-44bd-b966-fd563b71661f": {"__data__": {"id_": "8378b0a8-5338-44bd-b966-fd563b71661f", "embedding": null, "metadata": {"file_path": "/home/rojaldo/cursos/llm/llamaindex/docs/ia.md", "file_name": "ia.md", "file_type": "text/markdown", "file_size": 20595, "creation_date": "2025-06-04", "last_modified_date": "2025-06-04"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "efaff6ab-6f5b-4126-bcc7-1d17ce5e25e4", "node_type": "4", "metadata": {"file_path": "/home/rojaldo/cursos/llm/llamaindex/docs/ia.md", "file_name": "ia.md", "file_type": "text/markdown", "file_size": 20595, "creation_date": "2025-06-04", "last_modified_date": "2025-06-04"}, "hash": "5e327376077faf09c956464df4f5f70c8266bcfad3fad5763b907542011a5a33", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b34e700b-3828-4e7d-9b87-2842b478530e", "node_type": "1", "metadata": {"file_path": "/home/rojaldo/cursos/llm/llamaindex/docs/ia.md", "file_name": "ia.md", "file_type": "text/markdown", "file_size": 20595, "creation_date": "2025-06-04", "last_modified_date": "2025-06-04"}, "hash": "41af192bbaad64f68b4851fa77a3f262756d73ac99592446700d57b388469a47", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c3383793-fb39-45d9-bd18-918b23b92702", "node_type": "1", "metadata": {}, "hash": "5b9fa1ac957162b9c2a3fd3d55a1ed4b1afd34c27b7ffdf292e9e7f9a492c868", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "### Sistemas Expertos\n\nLos sistemas expertos, que representaban el conocimiento en forma de reglas if-then y utilizaban motores de inferencia para razonar sobre ese conocimiento, fueron una de las primeras aplicaciones pr\u00e1cticas de la IA en campos como la medicina, la ingenier\u00eda y el diagn\u00f3stico.\n\n### Programaci\u00f3n Simb\u00f3lica\n\nSe desarrollaron lenguajes de programaci\u00f3n simb\u00f3lica como Lisp para manipular s\u00edmbolos y representar el conocimiento de una manera m\u00e1s abstracta, lo que facilitaba la implementaci\u00f3n de sistemas inteligentes.\n\n### Teor\u00eda de Juegos y Planificaci\u00f3n\n\nSe aplicaron principios de teor\u00eda de juegos y planificaci\u00f3n para desarrollar agentes inteligentes capaces de tomar decisiones en entornos complejos y competitivos.\n\n### Aprendizaje Autom\u00e1tico Simb\u00f3lico\n\nSurgieron enfoques de aprendizaje autom\u00e1tico basados en el razonamiento simb\u00f3lico, como el aprendizaje inductivo, que se centraba en la extracci\u00f3n de reglas y patrones a partir de ejemplos de datos.\n\n## Diferencia entre Machine Learning y Deep Learning\n\n### Machine Learning (ML)\n\nEl Machine Learning se refiere a un conjunto de t\u00e9cnicas que permiten a los ordenadores aprender patrones o realizar tareas espec\u00edficas sin ser expl\u00edcitamente programadas para ello.\n\n- Se basa en algoritmos que pueden aprender de datos y hacer predicciones o tomar decisiones basadas en esos datos. Estos algoritmos pueden ser supervisados, no supervisados o de aprendizaje por refuerzo.\n- Ejemplos de t\u00e9cnicas de Machine Learning incluyen regresi\u00f3n lineal, \u00e1rboles de decisi\u00f3n, m\u00e1quinas de vectores de soporte (Support Vector Machines), k-means clustering, entre otros.\n- En t\u00e9rminos de arquitectura, los modelos de Machine Learning pueden tener una o unas pocas capas, pero no son tan profundas o complejas como las redes neuronales profundas utilizadas en Deep Learning.\n\n### Deep Learning (DL)\n\nEl Deep Learning es una sub\u00e1rea del Machine Learning que se centra en el uso de algoritmos basados en redes neuronales artificiales con m\u00faltiples capas (a menudo muchas capas) para modelar y procesar datos.\n\n- Estas redes neuronales profundas est\u00e1n compuestas por m\u00faltiples capas de nodos interconectados que procesan la informaci\u00f3n de manera jer\u00e1rquica, extrayendo caracter\u00edsticas complejas de los datos de entrada.\n- El Deep Learning se ha vuelto muy popular y efectivo en \u00e1reas como el reconocimiento de im\u00e1genes, el procesamiento del lenguaje natural, la visi\u00f3n por computadora y otros problemas de percepci\u00f3n.\n- A diferencia de muchas t\u00e9cnicas de Machine Learning tradicionales, el Deep Learning requiere grandes cantidades de datos de entrenamiento y potencia computacional para ajustar correctamente los muchos par\u00e1metros de las redes neuronales profundas.\n\n## Tipos de Redes Neuronales\n\n### Redes Neuronales Artificiales (ANN)\n\nSon la forma m\u00e1s b\u00e1sica de redes neuronales, compuestas por capas de neuronas conectadas. Cada neurona est\u00e1 conectada a las neuronas de la capa siguiente.\n\n- Las capas de una red neuronal artificial pueden ser de tres tipos: capa de entrada, capas ocultas y capa de salida. Las capas ocultas son las capas intermedias entre la capa de entrada y la capa de salida.\n- La capa de entrada recibe los datos de entrada, la capa de salida produce los resultados y las capas ocultas realizan el procesamiento intermedio.\n- La capa de entrada define la dimensi\u00f3n de los datos de entrada, la capa de salida define la dimensi\u00f3n de los datos de salida y las capas ocultas definen la complejidad y la capacidad de aprendizaje del modelo.\n\n### Redes Neuronales Convolucionales (CNN)\n\nEspecialmente dise\u00f1adas para procesar datos con estructura de cuadr\u00edcula, como im\u00e1genes. Utilizan operaciones de convoluci\u00f3n para extraer caracter\u00edsticas importantes de los datos de entrada.\n\n- Las CNN son capaces de capturar patrones espaciales y de escala en las im\u00e1genes, lo que las hace muy efectivas en tareas de visi\u00f3n artificial, como la clasificaci\u00f3n de im\u00e1genes, la detecci\u00f3n de objetos y la segmentaci\u00f3n sem\u00e1ntica.", "mimetype": "text/plain", "start_char_idx": 3024, "end_char_idx": 7011, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c3383793-fb39-45d9-bd18-918b23b92702": {"__data__": {"id_": "c3383793-fb39-45d9-bd18-918b23b92702", "embedding": null, "metadata": {"file_path": "/home/rojaldo/cursos/llm/llamaindex/docs/ia.md", "file_name": "ia.md", "file_type": "text/markdown", "file_size": 20595, "creation_date": "2025-06-04", "last_modified_date": "2025-06-04"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "efaff6ab-6f5b-4126-bcc7-1d17ce5e25e4", "node_type": "4", "metadata": {"file_path": "/home/rojaldo/cursos/llm/llamaindex/docs/ia.md", "file_name": "ia.md", "file_type": "text/markdown", "file_size": 20595, "creation_date": "2025-06-04", "last_modified_date": "2025-06-04"}, "hash": "5e327376077faf09c956464df4f5f70c8266bcfad3fad5763b907542011a5a33", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8378b0a8-5338-44bd-b966-fd563b71661f", "node_type": "1", "metadata": {"file_path": "/home/rojaldo/cursos/llm/llamaindex/docs/ia.md", "file_name": "ia.md", "file_type": "text/markdown", "file_size": 20595, "creation_date": "2025-06-04", "last_modified_date": "2025-06-04"}, "hash": "022a95b9e4adc2aa1ef27c4993d84a280c8dbf3f81292bbb6a473e77617f0e56", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b5e4a2b1-142b-406b-b718-4363443b181d", "node_type": "1", "metadata": {}, "hash": "e6cd136df4ee772da0077fb96bf31976183eaa4e044d74b8617e3d24a10fb029", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "- La capa de entrada define la dimensi\u00f3n de los datos de entrada, la capa de salida define la dimensi\u00f3n de los datos de salida y las capas ocultas definen la complejidad y la capacidad de aprendizaje del modelo.\n\n### Redes Neuronales Convolucionales (CNN)\n\nEspecialmente dise\u00f1adas para procesar datos con estructura de cuadr\u00edcula, como im\u00e1genes. Utilizan operaciones de convoluci\u00f3n para extraer caracter\u00edsticas importantes de los datos de entrada.\n\n- Las CNN son capaces de capturar patrones espaciales y de escala en las im\u00e1genes, lo que las hace muy efectivas en tareas de visi\u00f3n artificial, como la clasificaci\u00f3n de im\u00e1genes, la detecci\u00f3n de objetos y la segmentaci\u00f3n sem\u00e1ntica.\n\n### Redes Neuronales Recurrentes (RNN)\n\nSon adecuadas para datos de secuencia, como texto o series temporales. Tienen conexiones de retroalimentaci\u00f3n que les permiten mantener y usar informaci\u00f3n a lo largo del tiempo.\n\n- Originalmente, las RNN fueron \u00fatiles en tareas como el procesamiento del lenguaje natural, la traducci\u00f3n autom\u00e1tica, la generaci\u00f3n de texto y la predicci\u00f3n de series temporales. En la actualidad, han sido reemplazadas en muchos casos por las redes neuronales LSTM y transformers.\n- El problema principal de las RNN es el desvanecimiento del gradiente, que dificulta el entrenamiento de redes grandes. El desvanecimiento del gradiente ocurre cuando los gradientes se vuelven muy peque\u00f1os a medida que se propagan hacia atr\u00e1s en el tiempo, lo que dificulta la actualizaci\u00f3n de los pesos de las capas anteriores.\n\n### Redes Neuronales Long Short-Term Memory (LSTM)\n\nUna variante de las RNN dise\u00f1ada para manejar problemas de desvanecimiento del gradiente. Las LSTM tienen unidades de memoria especiales que pueden aprender y recordar a largo plazo.\n\n- Las LSTM son ampliamente utilizadas en tareas de procesamiento del lenguaje natural, como la traducci\u00f3n autom\u00e1tica, la generaci\u00f3n de texto y la generaci\u00f3n de subt\u00edtulos de im\u00e1genes.\n\n### Redes Neuronales Generativas Adversarias (GAN)\n\nConsisten en dos redes neuronales, un generador y un discriminador, que compiten entre s\u00ed. El generador crea datos nuevos que intentan pasar como datos reales, mientras que el discriminador intenta distinguir entre los datos reales y los generados.\n\n- Las GAN supusieron un gran avance en la generaci\u00f3n de datos realistas y se utilizan en tareas de generaci\u00f3n de im\u00e1genes, video y audio, as\u00ed como en la mejora de la calidad de las im\u00e1genes y la generaci\u00f3n de datos sint\u00e9ticos.\n\n### Redes Neuronales Siamesas\n\nUtilizadas en tareas de comparaci\u00f3n o identificaci\u00f3n de similitudes. Consisten en dos ramas de redes neuronales que comparten los mismos par\u00e1metros y procesan dos entradas para producir vectores de caracter\u00edsticas que luego se comparan.\n\n### Redes Neuronales Autoencoder\n\nUtilizadas para el aprendizaje no supervisado, comprimen los datos de entrada en un espacio de representaci\u00f3n m\u00e1s peque\u00f1o y luego los reconstruyen. Pueden ser utilizadas para la reducci\u00f3n de dimensionalidad, la generaci\u00f3n de datos y la detecci\u00f3n de anomal\u00edas.\n\n### Redes Neuronales Residuales (ResNet)\n\nIntroducen conexiones de \"salto\" que permiten que las se\u00f1ales de entrada y salida se agreguen directamente entre capas. Esto facilita el entrenamiento de redes m\u00e1s profundas al evitar problemas de desvanecimiento del gradiente.\n\n### Redes Neuronales Transformer\n\nIntroducen un mecanismo de atenci\u00f3n que permite a las redes neuronales procesar secuencias de datos de manera paralela y capturar relaciones a largo plazo entre elementos de la secuencia.\n\n- Los transformers han demostrado ser muy efectivos en tareas de procesamiento del lenguaje natural, como la traducci\u00f3n autom\u00e1tica, la generaci\u00f3n de texto y la respuesta a preguntas.\n- La gran ventaja de los transformers es su capacidad para capturar relaciones a largo plazo en las secuencias de datos, y permiten ser entrenados de manera m\u00e1s escalable y eficiente que modelos anteriores.\n\n### Redes Neuronales de difusores\n\nSon un tipo de red neuronal generativa que modela la distribuci\u00f3n de probabilidad de los datos de entrada.", "mimetype": "text/plain", "start_char_idx": 6330, "end_char_idx": 10386, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b5e4a2b1-142b-406b-b718-4363443b181d": {"__data__": {"id_": "b5e4a2b1-142b-406b-b718-4363443b181d", "embedding": null, "metadata": {"file_path": "/home/rojaldo/cursos/llm/llamaindex/docs/ia.md", "file_name": "ia.md", "file_type": "text/markdown", "file_size": 20595, "creation_date": "2025-06-04", "last_modified_date": "2025-06-04"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "efaff6ab-6f5b-4126-bcc7-1d17ce5e25e4", "node_type": "4", "metadata": {"file_path": "/home/rojaldo/cursos/llm/llamaindex/docs/ia.md", "file_name": "ia.md", "file_type": "text/markdown", "file_size": 20595, "creation_date": "2025-06-04", "last_modified_date": "2025-06-04"}, "hash": "5e327376077faf09c956464df4f5f70c8266bcfad3fad5763b907542011a5a33", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c3383793-fb39-45d9-bd18-918b23b92702", "node_type": "1", "metadata": {"file_path": "/home/rojaldo/cursos/llm/llamaindex/docs/ia.md", "file_name": "ia.md", "file_type": "text/markdown", "file_size": 20595, "creation_date": "2025-06-04", "last_modified_date": "2025-06-04"}, "hash": "f095464016b56fa89ca1e42752545df088e5a2a212f92f9d3252b12c3cafa794", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c4331a8a-42fe-4ef4-9883-02a7bc2e939f", "node_type": "1", "metadata": {}, "hash": "f2df12a4a3e8672b80222475ecd5040920c54acad96e0a2fc216e4f88aa03619", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Esto facilita el entrenamiento de redes m\u00e1s profundas al evitar problemas de desvanecimiento del gradiente.\n\n### Redes Neuronales Transformer\n\nIntroducen un mecanismo de atenci\u00f3n que permite a las redes neuronales procesar secuencias de datos de manera paralela y capturar relaciones a largo plazo entre elementos de la secuencia.\n\n- Los transformers han demostrado ser muy efectivos en tareas de procesamiento del lenguaje natural, como la traducci\u00f3n autom\u00e1tica, la generaci\u00f3n de texto y la respuesta a preguntas.\n- La gran ventaja de los transformers es su capacidad para capturar relaciones a largo plazo en las secuencias de datos, y permiten ser entrenados de manera m\u00e1s escalable y eficiente que modelos anteriores.\n\n### Redes Neuronales de difusores\n\nSon un tipo de red neuronal generativa que modela la distribuci\u00f3n de probabilidad de los datos de entrada. Utilizan una serie de transformaciones invertibles para mapear los datos de entrada a un espacio latente y viceversa.\n\n### Redes Neuronales de aprendizaje por refuerzo (RL)\n\nSe utilizan para entrenar agentes inteligentes que toman decisiones secuenciales en entornos din\u00e1micos. Los agentes aprenden a maximizar una recompensa acumulada a lo largo del tiempo.\n\n- El campo del aprendizaje por refuerzo ha experimentado un gran avance en los \u00faltimos a\u00f1os, con el desarrollo de algoritmos como DQN, A2C, PPO y DDPG, que han demostrado un rendimiento sobresaliente en tareas de control y juegos.\n\n## Tipos de modelos de IA\n\n### Modelos de Aprendizaje Supervisado\n\nLos modelos de aprendizaje supervisado se entrenan con ejemplos de entrada y salida emparejados. El objetivo es aprender una funci\u00f3n que mapee las entradas a las salidas.\n\n- Ejemplos de modelos de aprendizaje supervisado incluyen regresi\u00f3n lineal, regresi\u00f3n log\u00edstica, m\u00e1quinas de vectores de soporte (SVM), \u00e1rboles de decisi\u00f3n, bosques aleatorios, redes neuronales, entre otros.\n- Estos modelos se utilizan en tareas como la clasificaci\u00f3n, la regresi\u00f3n, la detecci\u00f3n de anomal\u00edas y la generaci\u00f3n de texto.\n\n### Modelos de Aprendizaje No Supervisado\n\nLos modelos de aprendizaje no supervisado se entrenan con datos de entrada sin etiquetar. El objetivo es encontrar patrones, estructuras o relaciones interesantes en los datos.\n\n- Ejemplos de modelos de aprendizaje no supervisado incluyen clustering, reducci\u00f3n de dimensionalidad, reglas de asociaci\u00f3n y aprendizaje de densidad.\n- Estos modelos se utilizan en tareas como la segmentaci\u00f3n de clientes, la detecci\u00f3n de fraudes, la recomendaci\u00f3n de productos y la visualizaci\u00f3n de datos.\n\n### Modelos de Aprendizaje por Refuerzo\n\nLos modelos de aprendizaje por refuerzo se entrenan con un sistema de recompensa y castigo. El objetivo es aprender una pol\u00edtica que maximice la recompensa acumulada a lo largo del tiempo.\n\n- Ejemplos de modelos de aprendizaje por refuerzo incluyen Q-learning, SARSA, DQN, A2C, PPO y DDPG.\n- Estos modelos se utilizan en tareas como el control de robots, los juegos, la optimizaci\u00f3n de carteras y la toma de decisiones secuenciales.\n\n### Modelos de Aprendizaje Semi-Supervisado\n\nLos modelos de aprendizaje semi-supervisado se entrenan con una combinaci\u00f3n de datos etiquetados y no etiquetados. El objetivo es aprovechar la informaci\u00f3n no etiquetada para mejorar el rendimiento del modelo.\n\n- Ejemplos de modelos de aprendizaje semi-supervisado incluyen la propagaci\u00f3n de etiquetas, la autoetiquetaci\u00f3n y la regularizaci\u00f3n de consistencia.\n- Estos modelos se utilizan en tareas donde es costoso o dif\u00edcil obtener grandes cantidades de datos etiquetados.\n\n### Modelos de Aprendizaje por Transferencia\n\nLos modelos de aprendizaje por transferencia se entrenan en un dominio fuente y se aplican en un dominio objetivo relacionado. El objetivo es transferir el conocimiento aprendido en el dominio fuente al dominio objetivo.\n\n- Ejemplos de modelos de aprendizaje por transferencia incluyen fine-tuning, pre-entrenamiento y adaptaci\u00f3n de dominio.", "mimetype": "text/plain", "start_char_idx": 9522, "end_char_idx": 13465, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c4331a8a-42fe-4ef4-9883-02a7bc2e939f": {"__data__": {"id_": "c4331a8a-42fe-4ef4-9883-02a7bc2e939f", "embedding": null, "metadata": {"file_path": "/home/rojaldo/cursos/llm/llamaindex/docs/ia.md", "file_name": "ia.md", "file_type": "text/markdown", "file_size": 20595, "creation_date": "2025-06-04", "last_modified_date": "2025-06-04"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "efaff6ab-6f5b-4126-bcc7-1d17ce5e25e4", "node_type": "4", "metadata": {"file_path": "/home/rojaldo/cursos/llm/llamaindex/docs/ia.md", "file_name": "ia.md", "file_type": "text/markdown", "file_size": 20595, "creation_date": "2025-06-04", "last_modified_date": "2025-06-04"}, "hash": "5e327376077faf09c956464df4f5f70c8266bcfad3fad5763b907542011a5a33", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b5e4a2b1-142b-406b-b718-4363443b181d", "node_type": "1", "metadata": {"file_path": "/home/rojaldo/cursos/llm/llamaindex/docs/ia.md", "file_name": "ia.md", "file_type": "text/markdown", "file_size": 20595, "creation_date": "2025-06-04", "last_modified_date": "2025-06-04"}, "hash": "bcba73875fbc4540a924263836a182b9958048c8c2a4106bc253710b035f7406", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ff402985-4272-4131-99bc-e16392610807", "node_type": "1", "metadata": {}, "hash": "cbe505904333aaab3b89f9ed671bd1ad5a952a3e7cbd578bb139efe282002edc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "El objetivo es aprovechar la informaci\u00f3n no etiquetada para mejorar el rendimiento del modelo.\n\n- Ejemplos de modelos de aprendizaje semi-supervisado incluyen la propagaci\u00f3n de etiquetas, la autoetiquetaci\u00f3n y la regularizaci\u00f3n de consistencia.\n- Estos modelos se utilizan en tareas donde es costoso o dif\u00edcil obtener grandes cantidades de datos etiquetados.\n\n### Modelos de Aprendizaje por Transferencia\n\nLos modelos de aprendizaje por transferencia se entrenan en un dominio fuente y se aplican en un dominio objetivo relacionado. El objetivo es transferir el conocimiento aprendido en el dominio fuente al dominio objetivo.\n\n- Ejemplos de modelos de aprendizaje por transferencia incluyen fine-tuning, pre-entrenamiento y adaptaci\u00f3n de dominio.\n- Los modelos de aprendizaje por transferencia se utilizan en tareas donde hay poca cantidad de datos en el dominio objetivo o donde el entrenamiento desde cero es costoso.\n\n## Modelos de IA pre-entrenados\n\nLos modelos de IA pre-entrenados son modelos que han sido entrenados en grandes conjuntos de datos y que se pueden utilizar directamente o ajustar para tareas espec\u00edficas.\n\n### Conceptos Relacionados con Modelos de IA pre-entrenados\n\n- **Checkpoints (Puntos de control):** Instant\u00e1neas guardadas del estado del modelo durante el proceso de entrenamiento en IA. Se utilizan para reanudar el entrenamiento o para realizar inferencias. En un checkpoint se guardan los pesos, los hiperpar\u00e1metros y otros datos del modelo.\n- **Transfer Learning (Aprendizaje por transferencia):** T\u00e9cnica en la que un modelo entrenado para una tarea espec\u00edfica se reutiliza como punto de partida para entrenar otro modelo para una tarea relacionada o diferente.\n- **Hypernetworks (Hiperredes):** Clase de modelos de redes neuronales utilizados para generar pesos o par\u00e1metros de otras redes neuronales. Se utilizan para aprender representaciones de datos o para generar arquitecturas de redes neuronales.\n- **Data Augmentation (Aumento de datos):** T\u00e9cnica para aumentar la cantidad y diversidad de datos de entrenamiento mediante transformaciones aleatorias o controladas.\n- **Adversarial Training (Entrenamiento adversarial):** T\u00e9cnica de entrenamiento para modelos generativos que implica entrenar simult\u00e1neamente un generador y un discriminador.\n- **Self-Attention (Autoatenci\u00f3n):** Mecanismo utilizado en arquitecturas de redes neuronales, especialmente en modelos de lenguaje como Transformers.\n- **Latent Space (Espacio latente):** Espacio de representaci\u00f3n de caracter\u00edsticas latentes aprendidas por un modelo generativo.\n- **Fine-Tuning (Ajuste fino):** T\u00e9cnica de ajuste de un modelo pre-entrenado en un conjunto de datos espec\u00edfico para mejorar su rendimiento en una tarea espec\u00edfica.\n- **Inference (Inferencia):** Proceso de utilizar un modelo entrenado para hacer predicciones sobre nuevos datos de entrada.\n\n## Principales Librer\u00edas de Inteligencia Artificial\n\n- **TensorFlow:** Desarrollada por Google, una de las librer\u00edas m\u00e1s populares para construir y entrenar modelos de IA y DL. [TensorFlow](https://www.tensorflow.org)\n- **PyTorch:** Desarrollada por Facebook, muy popular en la investigaci\u00f3n y el desarrollo de prototipos. [PyTorch](https://pytorch.org/)\n- **Scikit-learn:** Librer\u00eda de aprendizaje autom\u00e1tico en Python para algoritmos supervisados y no supervisados. [Scikit-learn](https://scikit-learn.org/)\n- **Keras:** Librer\u00eda de alto nivel para la construcci\u00f3n de redes neuronales en Python que puede ejecutarse sobre TensorFlow, Theano o CNTK. [Keras](https://keras.io/)\n- **MXNet:** Librer\u00eda de c\u00f3digo abierto para el desarrollo de modelos de IA y DL. [MXNet](https://mxnet.apache.org/)\n- **Caffe:** Librer\u00eda especialmente dise\u00f1ada para visi\u00f3n por computadora y CNN. [Caffe](https://caffe.berkeleyvision.org/)\n- **OpenCV:** Librer\u00eda de visi\u00f3n por computadora de c\u00f3digo abierto. [OpenCV](https://opencv.org/)\n- **NLTK (Natural Language Toolkit):** Librer\u00eda de Python para el procesamiento del lenguaje natural.", "mimetype": "text/plain", "start_char_idx": 12718, "end_char_idx": 16690, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ff402985-4272-4131-99bc-e16392610807": {"__data__": {"id_": "ff402985-4272-4131-99bc-e16392610807", "embedding": null, "metadata": {"file_path": "/home/rojaldo/cursos/llm/llamaindex/docs/ia.md", "file_name": "ia.md", "file_type": "text/markdown", "file_size": 20595, "creation_date": "2025-06-04", "last_modified_date": "2025-06-04"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "efaff6ab-6f5b-4126-bcc7-1d17ce5e25e4", "node_type": "4", "metadata": {"file_path": "/home/rojaldo/cursos/llm/llamaindex/docs/ia.md", "file_name": "ia.md", "file_type": "text/markdown", "file_size": 20595, "creation_date": "2025-06-04", "last_modified_date": "2025-06-04"}, "hash": "5e327376077faf09c956464df4f5f70c8266bcfad3fad5763b907542011a5a33", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c4331a8a-42fe-4ef4-9883-02a7bc2e939f", "node_type": "1", "metadata": {"file_path": "/home/rojaldo/cursos/llm/llamaindex/docs/ia.md", "file_name": "ia.md", "file_type": "text/markdown", "file_size": 20595, "creation_date": "2025-06-04", "last_modified_date": "2025-06-04"}, "hash": "c16db03cdb9733b7efaf31026d21d2a396ebe2c78b3765a8fc89d1fef1bb2f73", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "08768263-fa37-4ac9-8f5f-91eb7df23e49", "node_type": "1", "metadata": {}, "hash": "2393f9faf660d546903786e8aa08b13db90d5fdfc47fb38410989a3e537e491c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[Scikit-learn](https://scikit-learn.org/)\n- **Keras:** Librer\u00eda de alto nivel para la construcci\u00f3n de redes neuronales en Python que puede ejecutarse sobre TensorFlow, Theano o CNTK. [Keras](https://keras.io/)\n- **MXNet:** Librer\u00eda de c\u00f3digo abierto para el desarrollo de modelos de IA y DL. [MXNet](https://mxnet.apache.org/)\n- **Caffe:** Librer\u00eda especialmente dise\u00f1ada para visi\u00f3n por computadora y CNN. [Caffe](https://caffe.berkeleyvision.org/)\n- **OpenCV:** Librer\u00eda de visi\u00f3n por computadora de c\u00f3digo abierto. [OpenCV](https://opencv.org/)\n- **NLTK (Natural Language Toolkit):** Librer\u00eda de Python para el procesamiento del lenguaje natural. [NLTK](https://www.nltk.org/)\n\n## Enlaces de Inter\u00e9s\n\n### Conceptos B\u00e1sicos de IA\n\n- [Inteligencia Artificial en Wikipedia](https://es.wikipedia.org/wiki/Inteligencia_artificial)\n- [Historia de la Inteligencia Artificial](https://www.ibm.com/cloud/learn/what-is-artificial-intelligence)\n- [Tensorflow Playground](https://playground.tensorflow.org/)\n\n### Empresas relevantes en IA\n\n- [OpenAI](https://openai.com/)\n- [DeepMind](https://deepmind.com/)\n- [IBM Watson](https://www.ibm.com/watson)\n\n### Plataformas y Comunidades\n\n- [Hugging Face](https://huggingface.co/)\n- [Kaggle](https://www.kaggle.com/)\n- [Ollama](https://ollama.com/)\n- [Civit AI](https://civitai.com/)\n\n### Miscel\u00e1nea\n\n- [Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)\n- [KDnuggets](https://www.kdnuggets.com/)\n- [arXiv](https://www.arxiv.org/)\n- [Papers with Code](https://www.paperswithcode.com/)\n\n## Anexo 1: Modelos de IA Pre-entrenados\n\n### Modelos generativos de lenguaje\n\n- **GPT-X (Generative Pre-trained Transformer X):** Modelo de lenguaje generativo de OpenAI.\n- **[Llama](https://llama.meta.com/):** Modelo de lenguaje generativo de Meta, con muchas variantes y modelos especializados.\n- **[gemma](https://ollama.com/library/gemma):** Modelo de lenguaje generativo de Google (Deepmind).\n- **[Mistral](https://docs.mistral.ai/):** Modelo de lenguaje generativo de Mistral, con variantes como Mixtral y Dolphin-Mixtral.\n- **[Qwen](https://github.com/QwenLM/Qwen):** Modelo de lenguaje generativo de Alibaba.\n- **[Llava](https://llava-vl.github.io/):** Modelo multimodal que combina texto y visi\u00f3n.\n\n### Modelos generativos de im\u00e1genes\n\n- **[DALL-E 2](https://openai.com/dall-e-2/):** Modelo generativo de im\u00e1genes de OpenAI.\n- **[MidJourney](https://www.midjourney.com/home):** Modelo generativo de im\u00e1genes de MidJourney.\n- **[Stable Diffusion](https://stability.ai/stable-image):** Modelo generativo de im\u00e1genes de OpenAI.\n\n## Anexo 2: Hitos y Logros de DeepMind\n\nDeepMind es una empresa de inteligencia artificial con sede en Londres, fundada en 2010 y adquirida por Google en 2014. Ha logrado varios hitos y avances significativos en el campo de la inteligencia artificial.\n\n### AlphaGo\n\n- En 2016, AlphaGo, desarrollado por DeepMind, derrot\u00f3 al campe\u00f3n mundial de Go, Lee Sedol, en una serie de juegos hist\u00f3ricos. AlphaGo demostr\u00f3 la capacidad de las redes neuronales para dominar un juego complejo de estrategia, superando el nivel humano.\n- [AlphaGo - The Movie](https://youtu.be/WXuK6gekU1Y)\n\n### AlphaZero\n\n- En 2017, DeepMind present\u00f3 AlphaZero, un sistema de IA capaz de aprender a jugar Go, ajedrez y shogi sin datos de entrenamiento humanos.", "mimetype": "text/plain", "start_char_idx": 16041, "end_char_idx": 19363, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "08768263-fa37-4ac9-8f5f-91eb7df23e49": {"__data__": {"id_": "08768263-fa37-4ac9-8f5f-91eb7df23e49", "embedding": null, "metadata": {"file_path": "/home/rojaldo/cursos/llm/llamaindex/docs/ia.md", "file_name": "ia.md", "file_type": "text/markdown", "file_size": 20595, "creation_date": "2025-06-04", "last_modified_date": "2025-06-04"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "efaff6ab-6f5b-4126-bcc7-1d17ce5e25e4", "node_type": "4", "metadata": {"file_path": "/home/rojaldo/cursos/llm/llamaindex/docs/ia.md", "file_name": "ia.md", "file_type": "text/markdown", "file_size": 20595, "creation_date": "2025-06-04", "last_modified_date": "2025-06-04"}, "hash": "5e327376077faf09c956464df4f5f70c8266bcfad3fad5763b907542011a5a33", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ff402985-4272-4131-99bc-e16392610807", "node_type": "1", "metadata": {"file_path": "/home/rojaldo/cursos/llm/llamaindex/docs/ia.md", "file_name": "ia.md", "file_type": "text/markdown", "file_size": 20595, "creation_date": "2025-06-04", "last_modified_date": "2025-06-04"}, "hash": "a29c61adf9891947858fbe076823aaed68d28da8149790ef4373a8d3c6d29170", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Ha logrado varios hitos y avances significativos en el campo de la inteligencia artificial.\n\n### AlphaGo\n\n- En 2016, AlphaGo, desarrollado por DeepMind, derrot\u00f3 al campe\u00f3n mundial de Go, Lee Sedol, en una serie de juegos hist\u00f3ricos. AlphaGo demostr\u00f3 la capacidad de las redes neuronales para dominar un juego complejo de estrategia, superando el nivel humano.\n- [AlphaGo - The Movie](https://youtu.be/WXuK6gekU1Y)\n\n### AlphaZero\n\n- En 2017, DeepMind present\u00f3 AlphaZero, un sistema de IA capaz de aprender a jugar Go, ajedrez y shogi sin datos de entrenamiento humanos.\n- [How Magnus Carlsen Learned From AlphaZero](https://youtu.be/I0zqbO622rg)\n\n### AlphaStar\n\n- En 2019, DeepMind present\u00f3 AlphaStar, un sistema de IA capaz de jugar StarCraft II a nivel de los mejores jugadores humanos.\n- [AlphaStar - The inside story](https://youtu.be/UuhECwm31dM)\n\n### AlphaFold\n\n- En 2020, DeepMind present\u00f3 AlphaFold, un sistema de IA para la predicci\u00f3n de la estructura de prote\u00ednas.\n- AlphaFold demostr\u00f3 una capacidad sin precedentes para predecir la estructura tridimensional de las prote\u00ednas, un avance significativo en la biolog\u00eda computacional.\n- [AlphaFold en YouTube](https://youtube.com/playlist?list=PLqYmG7hTraZAhkAh72kzzLC4r2O4VoVgz)\n\n### GNoMe\n\n- En 2023, DeepMind present\u00f3 GNoMe, un modelo que permite predecir materiales con propiedades espec\u00edficas a partir de su estructura at\u00f3mica y estructuras cristalinas.\n- [Millions of new materials discovered with deep learning](https://deepmind.google/discover/blog/millions-of-new-materials-discovered-with-deep-learning/)", "mimetype": "text/plain", "start_char_idx": 18795, "end_char_idx": 20364, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"efaff6ab-6f5b-4126-bcc7-1d17ce5e25e4": {"node_ids": ["b34e700b-3828-4e7d-9b87-2842b478530e", "8378b0a8-5338-44bd-b966-fd563b71661f", "c3383793-fb39-45d9-bd18-918b23b92702", "b5e4a2b1-142b-406b-b718-4363443b181d", "c4331a8a-42fe-4ef4-9883-02a7bc2e939f", "ff402985-4272-4131-99bc-e16392610807", "08768263-fa37-4ac9-8f5f-91eb7df23e49"], "metadata": {"file_path": "/home/rojaldo/cursos/llm/llamaindex/docs/ia.md", "file_name": "ia.md", "file_type": "text/markdown", "file_size": 20595, "creation_date": "2025-06-04", "last_modified_date": "2025-06-04"}}}}